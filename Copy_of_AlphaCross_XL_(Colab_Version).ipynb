{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjyotshenoy/alphacross-xl/blob/main/Copy_of_AlphaCross_XL_(Colab_Version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click on the Start Button or Press Ctrl(Cmd on Mac)+Enter\n",
        "# Widget UI Imports\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Layout\n",
        "from IPython.display import display, clear_output\n",
        "import requests, gdown, time, datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os, shutil\n",
        "import urllib.request\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from io import BytesIO\n",
        "import pathlib\n",
        "import zipfile\n",
        "import pathlib\n",
        "\n",
        "# Colab specific (Comment these out on local)\n",
        "from google.colab import files\n",
        "os.chdir('/content')\n",
        "\n",
        "\n",
        "# When Running the Cell again in Colab, all files in cwd must be deleted\n",
        "# To preserve memory\n",
        "# Can comment this when working on local\n",
        "\n",
        "main_base_dir_parent = os.getcwd()\n",
        "main_base_dir_parent_path = pathlib.Path(main_base_dir_parent)\n",
        "if 'AlphaCrossXL Files' in main_base_dir_parent:\n",
        "    os.chdir(main_base_dir_parent_path.parent)\n",
        "    main_base_dir_parent = os.getcwd()\n",
        "else:\n",
        "    pass\n",
        "try:\n",
        "    os.mkdir(os.path.join(main_base_dir_parent, \"AlphaCrossXL Files\"))\n",
        "    os.chdir(os.path.join(os.getcwd(), \"AlphaCrossXL Files\"))\n",
        "    main_base_dir = os.getcwd()\n",
        "except:\n",
        "    shutil.rmtree(os.path.join(main_base_dir_parent, \"AlphaCrossXL Files\"))\n",
        "    os.mkdir(os.path.join(main_base_dir_parent, \"AlphaCrossXL Files\"))\n",
        "    os.chdir(os.path.join(os.getcwd(), \"AlphaCrossXL Files\"))\n",
        "    main_base_dir = os.getcwd()\n",
        "os.chdir(main_base_dir)\n",
        "\n",
        "\n",
        "\n",
        "class AlphaCrossXLBackend:\n",
        "    def __init__(self):\n",
        "        self.data_file = None\n",
        "        self.fasta_db = None\n",
        "        self.main_base_dir_parent = None\n",
        "        self.base_dir = None\n",
        "        self.residue_distance_threshold = None\n",
        "        self.input_file_columns = None\n",
        "        self.input_uniprotid_column = None\n",
        "        self.input_peptide_a_column = None\n",
        "        self.input_peptide_b_column = None\n",
        "        self.input_link_site_a_column = None\n",
        "        self.input_link_site_b_column = None\n",
        "        self.input_xlink_types_column = None\n",
        "        self.x_link_types = None\n",
        "        self.user_x_link_type_chosen = None\n",
        "        self.is_protein_centric = False\n",
        "        self.is_visualization_allowed = False\n",
        "        self.is_manual_protein_struct = False\n",
        "        self.manual_protein_struct_file = None\n",
        "        self.are_manual_structures_verified = False\n",
        "\n",
        "        self.XLMS_cif_files_protein_names = None\n",
        "        self.erroneous_XLMS_cif_files_protein_names = []\n",
        "\n",
        "        self.XLMS_raw_input = None\n",
        "        self.XLMS_input = None\n",
        "        self.XLMS_proteins = None\n",
        "        self.XLMS_Chain_1 = None\n",
        "        self.XLMS_Chain_2 = None\n",
        "        self.fa = None\n",
        "        self.XLMS_DF = None\n",
        "        self.XLMS_DF_NO_DUPES_NO_SHARED = None\n",
        "        self.XLMS_proteins_with_structure_info = None\n",
        "        self.XLMS_proteins_with_structure_info_df = None\n",
        "        self.XLMS_proteins_without_structure_info = None\n",
        "        self.df_bplt = None\n",
        "        self.df_hplt = None\n",
        "        self.df_cplt = None\n",
        "\n",
        "    def initialize_input_file(self):\n",
        "        '''\n",
        "        Initializes the input data file for processing.\n",
        "\n",
        "        args:\n",
        "            None\n",
        "        creates:\n",
        "            self.input_file_columns\n",
        "            self.XLMS_raw_input\n",
        "        return: None\n",
        "\n",
        "        Improvement:\n",
        "        # first copy the input files to base_dir\n",
        "        # Join the base_dir with the filename to get the destination path\n",
        "        destination = os.path.join(base_dir, os.path.basename(original_path))\n",
        "\n",
        "        # Copy the file\n",
        "        shutil.copy2(original_path, destination)\n",
        "        '''\n",
        "\n",
        "        if self.data_file.endswith(\".csv\"):\n",
        "            self.XLMS_raw_input = pd.read_csv(self.data_file)\n",
        "        elif self.data_file.endswith(\".xlsx\"):\n",
        "            self.XLMS_raw_input = pd.read_excel(self.data_file)\n",
        "        else:\n",
        "            raise Exception(\"File Format Error\")\n",
        "\n",
        "        input_columns = list((self.XLMS_raw_input.columns))\n",
        "        self.input_file_columns = input_columns\n",
        "\n",
        "    def get_input_file_columns(self):\n",
        "        '''\n",
        "        This function returns the columns of the input file.\n",
        "\n",
        "        args:\n",
        "            None\n",
        "        creates:\n",
        "            None\n",
        "        return:\n",
        "            input_file_columns\n",
        "        '''\n",
        "        return self.input_file_columns\n",
        "\n",
        "    def set_input_file_columns(self, user_chosen_columns_dict, reset=False):\n",
        "        '''\n",
        "        This function sets the corresponding columns of the input file for further processing.\n",
        "\n",
        "        args:\n",
        "            user_chosen_columns_dict\n",
        "        creates:\n",
        "            self.XLMS_raw_input\n",
        "        return:\n",
        "            None\n",
        "        '''\n",
        "        if reset:\n",
        "            self.XLMS_raw_input.rename(\n",
        "                {\n",
        "                    \"Peptide A\": self.input_peptide_a_column,\n",
        "                    \"Residue 1\": self.input_link_site_a_column,\n",
        "                    \"Peptide B\": self.input_peptide_b_column,\n",
        "                    \"Residue 2\": self.input_link_site_b_column,\n",
        "                    \"X-link type\": self.input_xlink_types_column,\n",
        "                    \"uniprotID\": self.input_uniprotid_column,\n",
        "                },\n",
        "                axis=1,\n",
        "                inplace=True,\n",
        "            )\n",
        "        else:\n",
        "            self.input_peptide_a_column = user_chosen_columns_dict[\"Peptide A\"]\n",
        "            self.input_link_site_a_column = user_chosen_columns_dict[\"Residue 1\"]\n",
        "            self.input_peptide_b_column = user_chosen_columns_dict[\"Peptide B\"]\n",
        "            self.input_link_site_b_column = user_chosen_columns_dict[\"Residue 2\"]\n",
        "            self.input_xlink_types_column = user_chosen_columns_dict[\"X-link type\"]\n",
        "            self.input_uniprotid_column = user_chosen_columns_dict[\"uniprotID\"]\n",
        "\n",
        "            self.XLMS_raw_input.rename(\n",
        "                    {\n",
        "                        self.input_peptide_a_column: \"Peptide A\",\n",
        "                        self.input_link_site_a_column: \"Residue 1\",\n",
        "                        self.input_peptide_b_column: \"Peptide B\",\n",
        "                        self.input_link_site_b_column: \"Residue 2\",\n",
        "                        self.input_xlink_types_column: \"X-link type\",\n",
        "                        self.input_uniprotid_column: \"uniprotID\",\n",
        "                    },\n",
        "                    axis=1,\n",
        "                    inplace=True,\n",
        "            )\n",
        "\n",
        "\n",
        "    def get_input_xlink_types(self):\n",
        "        '''\n",
        "        This function returns the unique cross-link types found in input file.\n",
        "\n",
        "        args:\n",
        "            None\n",
        "        creates:\n",
        "            None\n",
        "        return:\n",
        "            x_link_types\n",
        "        '''\n",
        "        x_link_types = list(self.XLMS_raw_input[\"X-link type\"].unique())\n",
        "        self.x_link_types = x_link_types\n",
        "\n",
        "        return self.x_link_types\n",
        "\n",
        "    def set_input_xlink_type_threshold_dist(self, user_x_link_type_chosen, user_threshold_dist_chosen, reset=False):\n",
        "        '''\n",
        "        This function sets the cross-link type and threshold distance\n",
        "        chosen by the user.\n",
        "\n",
        "        args:\n",
        "            user_x_link_type_chosen\n",
        "        creates:\n",
        "            self.XLMS_input, self.XLMS_proteins,\n",
        "            self.XLMS_Chain_1, self.XLMS_Chain_2,\n",
        "            self.residue_distance_threshold\n",
        "        return:\n",
        "            None\n",
        "        '''\n",
        "        if reset:\n",
        "            self.XLMS_input = None\n",
        "            self.XLMS_proteins = None\n",
        "            self.XLMS_Chain_1 = None\n",
        "            self.XLMS_Chain_2 = None\n",
        "            self.residue_distance_threshold = None\n",
        "            self.user_x_link_type_chosen = None\n",
        "        else:\n",
        "            self.residue_distance_threshold = user_threshold_dist_chosen\n",
        "            self.user_x_link_type_chosen = user_x_link_type_chosen\n",
        "\n",
        "            self.XLMS_input = self.XLMS_raw_input[\n",
        "                self.XLMS_raw_input[\"X-link type\"] == self.user_x_link_type_chosen\n",
        "            ]\n",
        "\n",
        "            self.XLMS_proteins = self.XLMS_input[\"uniprotID\"].unique()\n",
        "            self.XLMS_Chain_1 = self.XLMS_input[\"Peptide A\"].unique()\n",
        "            self.XLMS_Chain_2 = self.XLMS_input[\"Peptide B\"].unique()\n",
        "\n",
        "    def process_fasta(self):\n",
        "        '''\n",
        "        This function processes the FASTA file.\n",
        "\n",
        "        Improvement Suggestion: Instead of FASTA Database Upload\n",
        "        Just download FASTA on the fly\n",
        "        Snippet:\n",
        "        uurl = \"https://rest.uniprot.org/uniprotkb/stream?\"\n",
        "        output_format = \"compressed=false&fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Corganism_name%2Clength%2Csequence%2Cxref_pdb&format=tsv\"\n",
        "        uurl += output_format\n",
        "        query = \"model_organism%3A9606%20AND%20(reviewed:true)%20AND%20(database:pdb)%20AND%20(database:alphafolddb)\"\n",
        "        uurl += \"&query=\" + query\n",
        "        ureq = requests.get(uurl)\n",
        "        udata = pd.read_csv(BytesIO(ureq.content), delimiter=\"\\t\")\n",
        "\n",
        "        args:\n",
        "            None\n",
        "        creates:\n",
        "            self.fa\n",
        "        return:\n",
        "            None\n",
        "        '''\n",
        "        import pyfastx as pyfx\n",
        "\n",
        "        self.fa = pyfx.Fasta(self.fasta_db, key_func=lambda x: x.split(\"|\")[1], )\n",
        "\n",
        "    def verify_and_process_manual_protein_struct_file(self, reset=False):\n",
        "        \"\"\"\n",
        "        Verify and process uploaded protein structure files.\n",
        "\n",
        "        args:\n",
        "            reset (bool, optional): If True, reset all manual structure data. Defaults to False.\n",
        "        creates:\n",
        "            self.XLMS_cif_files_protein_names\n",
        "            self.are_manual_structures_verified\n",
        "            self.manual_protein_struct_file\n",
        "            self.is_manual_protein_struct\n",
        "        raises:\n",
        "            Exception: If no .CIF files are found or processing fails\n",
        "        return:\n",
        "            None\n",
        "        \"\"\"\n",
        "        if self.manual_protein_struct_file is not None and self.is_manual_protein_struct and not reset:\n",
        "            try:\n",
        "                os.mkdir(os.path.join(self.base_dir,\"Uploaded Structures\"))\n",
        "                os.chdir(os.path.join(self.base_dir,\"Uploaded Structures\"))\n",
        "            except:\n",
        "                shutil.rmtree(os.path.join(self.base_dir, \"Uploaded Structures\"))\n",
        "                os.mkdir(os.path.join(self.base_dir,\"Uploaded Structures\"))\n",
        "                os.chdir(os.path.join(self.base_dir,\"Uploaded Structures\"))\n",
        "\n",
        "            with zipfile.ZipFile(self.manual_protein_struct_file, 'r') as zip_ref:\n",
        "                zip_ref.extractall(os.path.join(self.base_dir,\"Uploaded Structures\"))\n",
        "\n",
        "            self.XLMS_cif_files_protein_names = [name[:-4] for name in os.listdir(\".\") if name.endswith(\".cif\")]\n",
        "\n",
        "            if len(self.XLMS_cif_files_protein_names) == 0:\n",
        "                clear_output()\n",
        "                os.chdir(self.base_dir)\n",
        "                shutil.rmtree(os.path.join(self.base_dir, \"Uploaded Structures\"))\n",
        "                self.XLMS_cif_files_protein_names = None\n",
        "                self.are_manual_structures_verified = False\n",
        "                self.manual_protein_struct_file = None\n",
        "                self.is_manual_protein_struct = False\n",
        "                print(\"No .CIF Structure Files Found\")\n",
        "            else:\n",
        "                self.are_manual_structures_verified = True\n",
        "                print(\"Verified Manual Protein Structure Files\")\n",
        "                print(\".CIF Files for UniProt IDs: \", self.XLMS_cif_files_protein_names)\n",
        "                print(\"Please note: It's your responsibility to make sure the .CIF files are named appropriately.\")\n",
        "            os.chdir(self.base_dir)\n",
        "        elif reset:\n",
        "            os.chdir(self.base_dir)\n",
        "            shutil.rmtree(os.path.join(self.base_dir, \"Uploaded Structures\"))\n",
        "            self.XLMS_cif_files_protein_names = None\n",
        "            self.are_manual_structures_verified = False\n",
        "            self.manual_protein_struct_file = None\n",
        "            self.is_manual_protein_struct = False\n",
        "\n",
        "        else:\n",
        "            raise Exception(\"Error in workflow: verify_and_process_manual_protein_struct_file. Contact Development Team.\")\n",
        "\n",
        "    def cleanList(self, list_var):\n",
        "        \"\"\"\n",
        "        This function cleans the list and returns a string\n",
        "\n",
        "        args:\n",
        "            list_var: list of strings\n",
        "        return:\n",
        "            list_str: string of the list\n",
        "        \"\"\"\n",
        "        list_str = str(list_var)\n",
        "        list_str = list_str.replace(\"[\", \"\")\n",
        "        list_str = list_str.replace(\"]\", \"\")\n",
        "        list_str = list_str.replace(\"'\", \"\")\n",
        "        return list_str\n",
        "\n",
        "    def get_peptide_starts(self, row):\n",
        "        \"\"\"\n",
        "        This function returns the start positions of the peptides in the FASTA file\n",
        "        args:\n",
        "            row: row of the dataframe\n",
        "        return:\n",
        "            start_list_a: list of start positions of peptide A\n",
        "            start_list_b: list of start positions of peptide B\n",
        "        \"\"\"\n",
        "\n",
        "        peptide_a = re.compile(row[\"Peptide A\"])\n",
        "        peptide_b = re.compile(row[\"Peptide B\"])\n",
        "        start_list_a = []\n",
        "        start_list_b = []\n",
        "\n",
        "        for m in peptide_a.finditer(self.fa[row[\"uniprotID\"]].seq):\n",
        "            start_list_a.append(m.start())\n",
        "\n",
        "        for m in peptide_b.finditer(self.fa[row[\"uniprotID\"]].seq):\n",
        "            start_list_b.append(m.start())\n",
        "\n",
        "        return [start_list_a, start_list_b]\n",
        "\n",
        "    def peptide_start_a(self, row):\n",
        "        \"\"\"\n",
        "        This function cleans the list of the start positions of peptides\n",
        "        args:\n",
        "            row: row of the dataframe\n",
        "        return:\n",
        "            list_str: string of the list of peptide A\n",
        "        \"\"\"\n",
        "        return self.cleanList(row[0])\n",
        "\n",
        "    def peptide_start_b(self, row):\n",
        "        \"\"\"\n",
        "        This function cleans the list of the start positions of peptides\n",
        "        args:\n",
        "            row: row of the dataframe\n",
        "        return:\n",
        "            list_str: string of the list of peptide B\n",
        "        \"\"\"\n",
        "\n",
        "        return self.cleanList(row[1])\n",
        "\n",
        "    def remove_shared_peptides(self, row):\n",
        "        \"\"\"\n",
        "        This function removes the shared peptides\n",
        "        args:\n",
        "            row: row of the dataframe\n",
        "        return:\n",
        "            True: if the peptides are not shared\n",
        "            False: if the peptides are shared\n",
        "        \"\"\"\n",
        "        if len(row[\"Peptide A-Pos\"]) > 0 and len(row[\"Peptide B-Pos\"]) > 0:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def get_actual_pos_from_residue_pep_a(self, row):\n",
        "        \"\"\"\n",
        "        This function returns the actual position of the residue in the chain\n",
        "        args:\n",
        "            row: row of the dataframe\n",
        "        return:\n",
        "            residue_a_loc: actual position of the residue in the chain\n",
        "\n",
        "        \"\"\"\n",
        "        peptide_a_start = int(row[\"Peptide A-Pos\"])\n",
        "        residue_a = row[\"Residue 1\"]\n",
        "        residue_a_loc = re.findall(r\"\\d+\", residue_a)\n",
        "        if len(residue_a_loc) == 1:\n",
        "            return int(residue_a_loc[0]) + peptide_a_start\n",
        "        else:\n",
        "            raise Exception(\"Residue Location Format Incorrect.\")\n",
        "\n",
        "    def get_actual_pos_from_residue_pep_b(self, row):\n",
        "        \"\"\"\n",
        "        This function returns the actual position of the residue in the chain\n",
        "        args:\n",
        "            row: row of the dataframe\n",
        "        return:\n",
        "            residue_b_loc: actual position of the residue in the chain\n",
        "        \"\"\"\n",
        "\n",
        "        peptide_b_start = int(row[\"Peptide B-Pos\"])\n",
        "        residue_b = row[\"Residue 2\"]\n",
        "        residue_b_loc = re.findall(r\"\\d+\", residue_b)\n",
        "        if len(residue_b_loc) == 1:\n",
        "            return int(residue_b_loc[0]) + peptide_b_start\n",
        "        else:\n",
        "            raise Exception(\"Residue Location Format Incorrect.\")\n",
        "\n",
        "    def convert_to_xlms_format(self):\n",
        "\n",
        "        temp = self.XLMS_input.apply(lambda row: self.get_peptide_starts(row), axis=1)\n",
        "        temp2 = temp.copy()\n",
        "\n",
        "        self.XLMS_input[\"Peptide A-Pos\"] = temp2.apply(\n",
        "            lambda row: self.peptide_start_a(row)\n",
        "        ).copy()\n",
        "        self.XLMS_input[\"Peptide B-Pos\"] = temp2.apply(\n",
        "            lambda row: self.peptide_start_b(row)\n",
        "        ).copy()\n",
        "\n",
        "        self.XLMS_DF = self.XLMS_input[\n",
        "            [\n",
        "                \"uniprotID\",\n",
        "                \"X-link type\",\n",
        "                \"Peptide A\",\n",
        "                \"Residue 1\",\n",
        "                \"Peptide A-Pos\",\n",
        "                \"Peptide B\",\n",
        "                \"Residue 2\",\n",
        "                \"Peptide B-Pos\",\n",
        "            ]\n",
        "        ].copy()\n",
        "\n",
        "        print(self.XLMS_DF.head())\n",
        "\n",
        "    # TO DO\n",
        "    # This function needs to be changed to accommodate protein centric formats\n",
        "    def calculate_absolute_chain_pos(self):\n",
        "        \"\"\"\n",
        "        Calculate absolute positions of cross-linking residues in protein chains.\n",
        "\n",
        "        Processes peptide positions to:\n",
        "            1. Filter out shared peptides\n",
        "            2. Calculate absolute positions for both peptides\n",
        "            3. Remove duplicates\n",
        "\n",
        "        Creates:\n",
        "            self.XLMS_DF_NO_DUPES_NO_SHARED: DataFrame with absolute positions and no duplicates\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If residue location format is incorrect\n",
        "        \"\"\"\n",
        "        def get_absolute_positions(df):\n",
        "            \"\"\"\n",
        "            Calculate absolute positions for both peptides in parallel.\n",
        "\n",
        "            Args:\n",
        "                df: DataFrame with peptide positions and residue information\n",
        "\n",
        "            Returns:\n",
        "                DataFrame with added absolute position columns\n",
        "            \"\"\"\n",
        "            def extract_residue_pos(pos_str, residue_col):\n",
        "                \"\"\"Extract and validate residue position.\"\"\"\n",
        "                try:\n",
        "                    peptide_start = int(pos_str)\n",
        "                    residue_num = re.findall(r\"\\d+\", residue_col)\n",
        "                    #print(residue_num)\n",
        "\n",
        "                    if len(residue_num) != 1:\n",
        "                        raise ValueError(f\"Invalid residue format in {residue_col}\")\n",
        "\n",
        "                    return int(residue_num[0]) + peptide_start\n",
        "                except ValueError as e:\n",
        "                    raise ValueError(f\"Position calculation failed: {str(e)}\")\n",
        "\n",
        "            # Filter rows where both peptides have valid positions\n",
        "            valid_peptides = (df[\"Peptide A-Pos\"].str.len() > 0) & (df[\"Peptide B-Pos\"].str.len() > 0)\n",
        "            df = df[valid_peptides].copy()\n",
        "            #df.to_csv(\"test.csv\")\n",
        "\n",
        "            # Calculate absolute positions for both peptides\n",
        "            try:\n",
        "                df[\"Absolute Peptide A-Pos\"] = df.apply(\n",
        "                    lambda row: extract_residue_pos(row[\"Peptide A-Pos\"], row[\"Residue 1\"]),\n",
        "                    axis=1\n",
        "                )\n",
        "                df[\"Absolute Peptide B-Pos\"] = df.apply(\n",
        "                    lambda row: extract_residue_pos(row[\"Peptide B-Pos\"], row[\"Residue 2\"]),\n",
        "                    axis=1\n",
        "                )\n",
        "            except ValueError as e:\n",
        "                raise ValueError(f\"Position calculation failed: {str(e)}\")\n",
        "\n",
        "            return df\n",
        "\n",
        "        try:\n",
        "            # Process positions and remove duplicates in one chain\n",
        "            self.XLMS_DF_NO_DUPES_NO_SHARED = (\n",
        "                self.XLMS_DF.pipe(get_absolute_positions)\n",
        "                            .drop_duplicates()\n",
        "                            .reset_index(drop=True)\n",
        "            )\n",
        "\n",
        "            # Log processing results\n",
        "            initial_count = len(self.XLMS_DF)\n",
        "            final_count = len(self.XLMS_DF_NO_DUPES_NO_SHARED)\n",
        "            shared_count = initial_count - len(self.XLMS_DF[\n",
        "                (self.XLMS_DF[\"Peptide A-Pos\"].str.len() > 0) &\n",
        "                (self.XLMS_DF[\"Peptide B-Pos\"].str.len() > 0)\n",
        "            ])\n",
        "            duplicate_count = initial_count - shared_count - final_count\n",
        "\n",
        "            print(f\"Processing summary:\")\n",
        "            print(f\"- Initial entries: {initial_count}\")\n",
        "            print(f\"- Shared peptides removed: {shared_count}\")\n",
        "            print(f\"- Duplicates removed: {duplicate_count}\")\n",
        "            print(f\"- Final entries: {final_count}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Chain position calculation failed: {str(e)}\")\n",
        "\n",
        "    def proteins_from_alphafold(self):\n",
        "        '''\n",
        "        This function downloads mmCIF protein structure files from AlphaFold Protein Structure Database\n",
        "        and stores them in a directory named AlphaFold Structures.\n",
        "\n",
        "        args:\n",
        "            None\n",
        "        creates:\n",
        "            self.XLMS_proteins_with_structure_info,\n",
        "            self.XLMS_proteins_left\n",
        "            AlphaFold Structures directory is created if it doesn't exist\n",
        "        return:\n",
        "            None\n",
        "        '''\n",
        "        current_working_dir = self.base_dir\n",
        "        clear_output()\n",
        "        try:\n",
        "            os.mkdir(os.path.join(self.base_dir, \"AlphaFold Structures\"))\n",
        "            os.chdir(os.path.join(self.base_dir, \"AlphaFold Structures\"))\n",
        "            print(\"Created Directory for AlphaFold Structures: \", os.getcwd())\n",
        "            self.XLMS_proteins_with_structure_info = []\n",
        "            self.XLMS_proteins_left = self.XLMS_proteins\n",
        "\n",
        "        except FileExistsError:\n",
        "            #shutil.rmtree(os.path.join(self.base_dir, \"AlphaFold Structures\"))\n",
        "            #os.mkdir(os.path.join(self.base_dir, \"AlphaFold Structures\"))\n",
        "            os.chdir(os.path.join(self.base_dir, \"AlphaFold Structures\"))\n",
        "            print(\"Directory for AlphaFold Structures already exists: \", os.getcwd())\n",
        "            #os.chdir('/content/AlphaFold Structures')\n",
        "            current_dir = os.getcwd()\n",
        "            sub_dir_list = [sub_dir[0].split('/')[-1] for sub_dir in os.walk(current_dir)]\n",
        "            sub_dir_list.remove('AlphaFold Structures')\n",
        "            irrelevant_sub_dir_list = [sub_dir for sub_dir in sub_dir_list if sub_dir not in self.XLMS_proteins]\n",
        "            for sub_dir in irrelevant_sub_dir_list:\n",
        "                shutil.rmtree(os.path.join(self.base_dir, \"AlphaFold Structures\", sub_dir))\n",
        "            relevant_sub_dir_list = [sub_dir for sub_dir in sub_dir_list if sub_dir in self.XLMS_proteins]\n",
        "            print(\"Irrelevant Sub-Directories were \")\n",
        "            self.XLMS_proteins_with_structure_info = relevant_sub_dir_list\n",
        "            self.XLMS_proteins_left = [protein for protein in self.XLMS_proteins if protein not in self.XLMS_proteins_with_structure_info]\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred while creating the directory: {e}\")\n",
        "\n",
        "        print(\"Downloading Structures from AlphaFold.\")\n",
        "        self.XLMS_proteins_without_structure_info = []\n",
        "        for protein in self.XLMS_proteins_left:\n",
        "            os.makedirs( # Not really required\n",
        "                os.path.join(self.base_dir, \"AlphaFold Structures\"), exist_ok=True\n",
        "            )\n",
        "            os.chdir(os.path.join(self.base_dir, \"AlphaFold Structures\"))\n",
        "            os.makedirs(\n",
        "                os.path.join(self.base_dir, \"AlphaFold Structures\", protein),\n",
        "                exist_ok=True,\n",
        "            )\n",
        "            os.chdir(os.path.join(self.base_dir, \"AlphaFold Structures\", protein))\n",
        "            try:\n",
        "                # Change this URL for updates to AlphaFold Structures\n",
        "                urllib.request.urlretrieve(\n",
        "                    f\"https://alphafold.ebi.ac.uk/files/AF-{protein}-F1-model_v4.cif\",\n",
        "                    f\"{protein}.cif\",\n",
        "                )\n",
        "                print(\n",
        "                    f\"AlphaFold Structure downloaded for the following protein: {protein}\"\n",
        "                )\n",
        "                self.XLMS_proteins_with_structure_info.append(protein)\n",
        "            except urllib.error.HTTPError as e:\n",
        "                os.chdir(os.path.join(self.base_dir, \"AlphaFold Structures\"))\n",
        "                os.rmdir(os.path.join(self.base_dir, \"AlphaFold Structures\", protein))\n",
        "                self.XLMS_proteins_without_structure_info.append(protein)\n",
        "                print(\n",
        "                    f\"AlphaFold Structure not downloaded/found for the following protein: {protein}\"\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(\n",
        "                    f\"An unexpected error occurred while processing protein {protein}: {e}\"\n",
        "                )\n",
        "        clear_output()\n",
        "        print(\"AlphaFold Structures downloaded in directory:\", os.path.join(self.base_dir, \"AlphaFold Structures\"))\n",
        "        print(\"AlphaFold Structures not found for: \", self.XLMS_proteins_without_structure_info)\n",
        "        os.chdir(current_working_dir)\n",
        "\n",
        "    def _get_manual_structure_distance_data(self, row):\n",
        "        \"\"\"\n",
        "        Calculate distance between two residues for uploaded .CIF structures.\n",
        "\n",
        "        Args:\n",
        "            row: DataFrame row containing protein and peptide information\n",
        "\n",
        "        Returns:\n",
        "            dict: Contains residue indices, numbers and distance or error status\n",
        "        \"\"\"\n",
        "        # Custom exceptions for specific error cases\n",
        "        class StructureError(Exception): pass\n",
        "        class MultipleChainError(StructureError): pass\n",
        "        class ResidueLocationError(StructureError): pass\n",
        "        class PeptideError(StructureError): pass\n",
        "\n",
        "        # Initialize default return dictionary\n",
        "        data_dict = {key: 'N/A' for key in [\n",
        "            'residue-1-start-resindex', 'residue-2-start-resindex',\n",
        "            'residue-1-start-resnum', 'residue-2-start-resnum',\n",
        "            'residue-distance'\n",
        "        ]}\n",
        "\n",
        "        if row['uniprotID'] not in self.XLMS_cif_files_protein_names:\n",
        "            return data_dict\n",
        "\n",
        "        try:\n",
        "            import prody as prd\n",
        "            from contextlib import suppress\n",
        "\n",
        "            # Load and validate structure\n",
        "            protein_struct = prd.parseMMCIF(os.path.join(self.base_dir, 'Uploaded Structures', f'{row[\"uniprotID\"]}.cif'))\n",
        "            protein_struct_hv = protein_struct.getHierView()\n",
        "\n",
        "            if len(list(protein_struct_hv)) != 1:\n",
        "                raise MultipleChainError(\"Structure file has multiple chains\")\n",
        "\n",
        "            chain = list(list(protein_struct_hv)[0])\n",
        "            protein_struct_seq = list(protein_struct_hv)[0].getSequence()\n",
        "            #protein_struct_residue_list = list(list(protein_struct_hv)[0])\n",
        "\n",
        "            # Find peptide positions\n",
        "            def find_peptide_pos(peptide):\n",
        "                matches = list(re.compile(peptide).finditer(protein_struct_seq))\n",
        "                if not matches:\n",
        "                    raise PeptideError(\"Peptide not found\")\n",
        "                if len(matches) > 1:\n",
        "                    raise PeptideError(\"Multiple peptide matches found\")\n",
        "                return matches[0].start()\n",
        "\n",
        "            peptide_positions = {\n",
        "                'A': find_peptide_pos(row['Peptide A']),\n",
        "                'B': find_peptide_pos(row['Peptide B'])\n",
        "            }\n",
        "\n",
        "            # Calculate residue positions\n",
        "            def get_residue_pos(residue_str, peptide_start):\n",
        "                residue_loc = re.findall(r\"\\d+\", residue_str)\n",
        "                if len(residue_loc) != 1:\n",
        "                    raise ResidueLocationError(\"Invalid residue format\")\n",
        "                return int(residue_loc[0]) + peptide_start\n",
        "\n",
        "            residue_positions = {\n",
        "                'A': get_residue_pos(row['Residue 1'], peptide_positions['A']),\n",
        "                'B': get_residue_pos(row['Residue 2'], peptide_positions['B'])\n",
        "            }\n",
        "\n",
        "            # Get residues and calculate distance\n",
        "            residues = {\n",
        "                'A': chain[residue_positions['A'] - 1],\n",
        "                'B': chain[residue_positions['B'] - 1]\n",
        "            }\n",
        "\n",
        "            ca_atoms = {\n",
        "                'A': residues['A'].getAtom('CA'),\n",
        "                'B': residues['B'].getAtom('CA')\n",
        "            }\n",
        "\n",
        "            if any(atom is None for atom in ca_atoms.values()):\n",
        "                raise StructureError(\"CA atom not found in residue\")\n",
        "\n",
        "            distance = prd.calcDistance(ca_atoms['A'], ca_atoms['B'])\n",
        "\n",
        "            return {\n",
        "                'residue-1-start-resindex': residues['A'].getResindex(),\n",
        "                'residue-2-start-resindex': residues['B'].getResindex(),\n",
        "                'residue-1-start-resnum': residues['A'].getResnum(),\n",
        "                'residue-2-start-resnum': residues['B'].getResnum(),\n",
        "                'residue-distance': distance\n",
        "            }\n",
        "\n",
        "        except StructureError as e:\n",
        "            error_type = e.__class__.__name__.replace('Error', ' Error')\n",
        "            data_dict['residue-distance'] = error_type\n",
        "            self.erroneous_XLMS_cif_files_protein_names.append(row['uniprotID'])\n",
        "            print(f'Unable to compute distance for protein {row[\"uniprotID\"]}: {str(e)}')\n",
        "            return data_dict\n",
        "\n",
        "        except AttributeError as e:\n",
        "            data_dict['residue-distance'] = 'Structure Error'\n",
        "            self.erroneous_XLMS_cif_files_protein_names.append(row['uniprotID'])\n",
        "            print(f'Unable to compute distance for protein {row[\"uniprotID\"]}: Structure file is not appropriate. {str(e)}')\n",
        "            return data_dict\n",
        "\n",
        "    def calculate_residue_distance_and_betas_all(self):\n",
        "        \"\"\"\n",
        "        Calculate distances and confidence scores for all residue pairs.\n",
        "\n",
        "        This function processes both AlphaFold structures and manual structures (if available) to compute:\n",
        "            - Residue-residue distances\n",
        "            - pLDDT confidence scores from AlphaFold\n",
        "            - Manual structure distances and residue information\n",
        "\n",
        "        The function avoids redundant structure loading by processing all metrics for each\n",
        "        structure in a single pass.\n",
        "        \"\"\"\n",
        "        import prody as prd\n",
        "        from pathlib import Path\n",
        "\n",
        "        def process_alphafold_metrics(row):\n",
        "            \"\"\"Helper function to process all AlphaFold metrics for a single row.\"\"\"\n",
        "            # Clear Ouput to avoid messy output slowing done\n",
        "            clear_output()\n",
        "\n",
        "            if row['uniprotID'] not in self.XLMS_proteins_with_structure_info:\n",
        "                return {'distance': 'N/A', 'beta1': 'N/A', 'beta2': 'N/A'}\n",
        "\n",
        "            try:\n",
        "                # Load structure once for all calculations\n",
        "                protein = row['uniprotID']\n",
        "                struct_path = Path(self.base_dir) / 'AlphaFold Structures' / protein / f'{protein}.cif'\n",
        "                protein_struct = prd.parseMMCIF(str(struct_path))\n",
        "                protein_struct_hv = protein_struct.getHierView()\n",
        "\n",
        "                # Get residues\n",
        "                pep_a_pos = int(row['Absolute Peptide A-Pos'])\n",
        "                pep_b_pos = int(row['Absolute Peptide B-Pos'])\n",
        "                res_1 = protein_struct_hv.getResidue(\"A\", pep_a_pos)\n",
        "                res_2 = protein_struct_hv.getResidue(\"A\", pep_b_pos)\n",
        "\n",
        "                # Get CA atoms and compute metrics\n",
        "                res_1_ca = res_1[\"CA\"]\n",
        "                res_2_ca = res_2[\"CA\"]\n",
        "\n",
        "                return {\n",
        "                    'distance': prd.calcDistance(res_1_ca, res_2_ca),\n",
        "                    'beta1': res_1_ca.getBeta(),\n",
        "                    'beta2': res_2_ca.getBeta()\n",
        "                }\n",
        "\n",
        "            except AttributeError:\n",
        "                print(f'Unable to compute metrics for protein: {row[\"uniprotID\"]}.\\nThe structure file is not appropriate.')\n",
        "                return {'distance': 'N/A', 'beta1': 'N/A', 'beta2': 'N/A'}\n",
        "\n",
        "        # Process AlphaFold metrics efficiently\n",
        "        metrics = self.XLMS_DF_NO_DUPES_NO_SHARED.apply(process_alphafold_metrics, axis=1)\n",
        "\n",
        "        # Update DataFrame with computed metrics\n",
        "        self.XLMS_DF_NO_DUPES_NO_SHARED[\"Residue Distance\"] = metrics.apply(lambda x: x['distance'])\n",
        "        self.XLMS_DF_NO_DUPES_NO_SHARED[\"Residue 1 pLDDT\"] = metrics.apply(lambda x: x['beta1'])\n",
        "        self.XLMS_DF_NO_DUPES_NO_SHARED[\"Residue 2 pLDDT\"] = metrics.apply(lambda x: x['beta2'])\n",
        "\n",
        "        # Process manual structure data if available\n",
        "        if self.are_manual_structures_verified:\n",
        "            manual_struct_data = self.XLMS_DF_NO_DUPES_NO_SHARED.apply(\n",
        "                lambda row: self._get_manual_structure_distance_data(row), axis=1\n",
        "            )\n",
        "\n",
        "            # Update DataFrame with manual structure metrics using dict comprehension\n",
        "            manual_metrics = {\n",
        "                'Residue Distance (Manual)': 'residue-distance',\n",
        "                'Residue 1 Index (Manual)': 'residue-1-start-resindex',\n",
        "                'Residue 2 Index (Manual)': 'residue-2-start-resindex',\n",
        "                'Residue 1 Number (Manual)': 'residue-1-start-resnum',\n",
        "                'Residue 2 Number (Manual)': 'residue-2-start-resnum'\n",
        "            }\n",
        "\n",
        "            for df_col, dict_key in manual_metrics.items():\n",
        "                self.XLMS_DF_NO_DUPES_NO_SHARED[df_col] = manual_struct_data.apply(\n",
        "                    lambda row: row[dict_key]\n",
        "                )\n",
        "\n",
        "\n",
        "    def _get_residue_info_for_duplicates(self, row, protein_id_field, protein_list, column_name):\n",
        "        \"\"\"\n",
        "        Helper function to get residue information for duplicates.\n",
        "\n",
        "        Args:\n",
        "            row: DataFrame row\n",
        "            protein_id_field: Field containing protein ID\n",
        "            protein_list: List of valid protein IDs\n",
        "            column_name: Name of column to extract data from\n",
        "\n",
        "        Returns:\n",
        "            Value from the specified column or appropriate 'N/A' message\n",
        "        \"\"\"\n",
        "        if row[protein_id_field] in protein_list:\n",
        "            protein = row[protein_id_field]\n",
        "            matching_rows = self.XLMS_DF_NO_DUPES_NO_SHARED[\n",
        "                self.XLMS_DF_NO_DUPES_NO_SHARED[protein_id_field] == protein\n",
        "            ][column_name]\n",
        "\n",
        "            if not matching_rows.empty:\n",
        "                value = matching_rows.iloc[0]\n",
        "                # Convert to float if it's a distance or pLDDT value and not 'N/A'\n",
        "                if column_name in ['Residue Distance', 'Residue 1 pLDDT', 'Residue 2 pLDDT'] and value != 'N/A':\n",
        "                    return float(value)\n",
        "                return value\n",
        "            return 'N/A as Shared Peptide'\n",
        "        return 'N/A'\n",
        "\n",
        "    def insert_values_for_duplicates(self):\n",
        "        \"\"\"\n",
        "        Insert duplicate values for residue distances and related metrics.\n",
        "\n",
        "        Processes both AlphaFold and manual structure data (if available) to add:\n",
        "            - Residue distances\n",
        "            - pLDDT scores\n",
        "            - Manual structure measurements\n",
        "            - Residue numbers and indices\n",
        "        \"\"\"\n",
        "        # Define columns and their corresponding parameters\n",
        "        alphafold_columns = {\n",
        "            'Residue Distance': ('uniprotID', self.XLMS_proteins_with_structure_info),\n",
        "            'Residue 1 pLDDT': ('uniprotID', self.XLMS_proteins_with_structure_info),\n",
        "            'Residue 2 pLDDT': ('uniprotID', self.XLMS_proteins_with_structure_info)\n",
        "        }\n",
        "\n",
        "        # Process AlphaFold data\n",
        "        for col_name, (id_field, protein_list) in alphafold_columns.items():\n",
        "            self.XLMS_input[col_name] = self.XLMS_input.apply(\n",
        "                lambda row: self._get_residue_info_for_duplicates(\n",
        "                    row, id_field, protein_list, col_name\n",
        "                ),\n",
        "                axis=1\n",
        "            )\n",
        "\n",
        "        # Process manual structure data if available\n",
        "        if self.are_manual_structures_verified:\n",
        "            manual_columns = {\n",
        "                'Residue Distance (Manual)': ('uniprotID', self.XLMS_cif_files_protein_names),\n",
        "                'Residue 1 Number (Manual)': ('uniprotID', self.XLMS_cif_files_protein_names),\n",
        "                'Residue 2 Number (Manual)': ('uniprotID', self.XLMS_cif_files_protein_names),\n",
        "                'Residue 1 Index (Manual)': ('uniprotID', self.XLMS_cif_files_protein_names),\n",
        "                'Residue 2 Index (Manual)': ('uniprotID', self.XLMS_cif_files_protein_names)\n",
        "            }\n",
        "\n",
        "            for col_name, (id_field, protein_list) in manual_columns.items():\n",
        "                self.XLMS_input[col_name] = self.XLMS_input.apply(\n",
        "                    lambda row: self._get_residue_info_for_duplicates(\n",
        "                        row, id_field, protein_list, col_name\n",
        "                    ),\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "    # Outputting the distances\n",
        "    def output_distances(self):\n",
        "        \"\"\"\n",
        "        Save all analysis results to output files.\n",
        "\n",
        "        Generates:\n",
        "            - Excel file with all cross-link distances\n",
        "            - CSV file with unique entries\n",
        "            - Structure-based information\n",
        "        \"\"\"\n",
        "\n",
        "        self.XLMS_input.to_excel(os.path.join(self.base_dir, \"xlms_input.xlsx\"))\n",
        "        path = os.path.join(\n",
        "            self.base_dir,\n",
        "            pathlib.Path(self.data_file).stem + \"_XLMS_Distances_WO_Duplicates.csv\",\n",
        "        )\n",
        "        print(path)\n",
        "        self.XLMS_DF_NO_DUPES_NO_SHARED.to_csv(\n",
        "            os.path.join(\n",
        "                self.base_dir,\n",
        "                pathlib.Path(self.data_file).stem + \"_XLMS_Distances_WO_Duplicates.csv\",\n",
        "            ),\n",
        "            index=False,\n",
        "        )\n",
        "\n",
        "        pd.Series(self.XLMS_proteins_with_structure_info).to_csv(\n",
        "            os.path.join(self.base_dir, \"xlms_proteins_with_structure_info.csv\")\n",
        "        )\n",
        "        input_with_distances = pd.read_excel(\n",
        "            os.path.join(self.base_dir, \"xlms_input.xlsx\")\n",
        "        )\n",
        "        temp_input = input_with_distances[\n",
        "            input_with_distances[\"Residue Distance\"] != \"N/A as Shared Peptide\"\n",
        "        ]\n",
        "        processed_input = temp_input[temp_input[\"Residue Distance\"] != \"N/A\"].copy()\n",
        "        processed_input.fillna(0, inplace=True)\n",
        "        processed_input.to_excel(\n",
        "            os.path.join(\n",
        "                self.base_dir, pathlib.Path(self.data_file).stem + \"_XLMS_Output.xlsx\"\n",
        "            ),\n",
        "            index=False,\n",
        "        )\n",
        "\n",
        "        # Define File Name\n",
        "        self.df_bplt = pd.read_csv(\n",
        "            os.path.join(\n",
        "                self.base_dir,\n",
        "                pathlib.Path(self.data_file).stem + \"_XLMS_Distances_WO_Duplicates.csv\",\n",
        "            )\n",
        "        )\n",
        "        self.df_hplt = pd.read_excel(\n",
        "            os.path.join(\n",
        "                self.base_dir, pathlib.Path(self.data_file).stem + \"_XLMS_Output.xlsx\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def save_barplot(self):\n",
        "        \"\"\"\n",
        "        Generate and save bar plot of residue distances.\n",
        "\n",
        "        Creates a bar plot showing residue distances with a threshold line based on self.residue_distance_threshold.\n",
        "        and saves it as a JPEG file.\n",
        "        \"\"\"\n",
        "        Barplot = self.df_bplt.plot.bar(y=\"Residue Distance\", rot=0)\n",
        "        plt.axhline(y=self.residue_distance_threshold, color=\"r\", linestyle=\"dashed\")\n",
        "        Barplot.set_title(\"Distance_Residue Bar_Plot\", fontdict={\"fontsize\": 12})\n",
        "        # Barplot.set_xlabel(\"Score_1\",fontdict= { 'fontsize': 10})\n",
        "        Barplot.axes.get_xaxis().set_visible(False)\n",
        "        Barplot.set_ylabel(\"Cα-Cα Distance\", fontdict={\"fontsize\": 10})\n",
        "        plt.savefig(\n",
        "            os.path.join(\n",
        "                self.base_dir,\n",
        "                pathlib.Path(self.data_file).stem + \"_XLMS_Distances_Barplot.jpeg\",\n",
        "            ),\n",
        "            dpi=600,\n",
        "            bbox_inches=\"tight\",\n",
        "        )\n",
        "        print(\"bp_done\")\n",
        "        plt.close()\n",
        "\n",
        "    def save_histplot(self):\n",
        "        \"\"\"\n",
        "        Generate and save histogram of residue distances with error handling for small datasets.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convert 'Residue Distance' to numeric, coercing errors to NaN\n",
        "            self.df_hplt['Residue Distance'] = pd.to_numeric(self.df_hplt['Residue Distance'], errors='coerce')\n",
        "\n",
        "            # Drop NaN values and check if we have enough data\n",
        "            valid_data = self.df_hplt.dropna(subset=['Residue Distance'])\n",
        "            if len(valid_data) == 0:\n",
        "                print(\"Warning: No valid distance data found for histogram\")\n",
        "                return\n",
        "\n",
        "            # Compute violation status\n",
        "            valid_data[\"Cα-Cα Distance status\"] = np.where(\n",
        "                valid_data[\"Residue Distance\"] <= self.residue_distance_threshold,\n",
        "                \"Satisfied\",\n",
        "                \"Violated\"\n",
        "            )\n",
        "\n",
        "            # Save the analysis results\n",
        "            output_excel_path = os.path.join(\n",
        "                self.base_dir,\n",
        "                pathlib.Path(self.data_file).stem + \"_XLMS_Final_Output.xlsx\"\n",
        "            )\n",
        "            valid_data.to_excel(output_excel_path)\n",
        "\n",
        "            # Create histogram with adjusted number of bins\n",
        "            plt.figure(figsize=(10, 6))\n",
        "\n",
        "            # Calculate appropriate number of bins based on data size\n",
        "            n_bins = min(max(5, len(valid_data) // 2), 140)  # At least 5 bins, at most 140\n",
        "\n",
        "            Histplot = sns.histplot(\n",
        "                data=valid_data,\n",
        "                x=\"Residue Distance\",\n",
        "                bins=n_bins,  # Adjusted number of bins\n",
        "                stat=\"probability\",\n",
        "                hue=\"Cα-Cα Distance status\",\n",
        "                binwidth=None,  # Let seaborn determine appropriate binwidth\n",
        "                palette={\"Satisfied\": \"green\", \"Violated\": \"red\"}\n",
        "            )\n",
        "\n",
        "            # Set labels and style\n",
        "            Histplot.set(\n",
        "                ylabel=\"Cross-links\",\n",
        "                xlabel=\"Cα-Cα Distance\"\n",
        "            )\n",
        "            plt.ylabel(\"Cross-links\", fontsize=10)\n",
        "            plt.xlabel(\"Cα-Cα Distance\", fontsize=10)\n",
        "\n",
        "            # Save the plot\n",
        "            output_plot_path = os.path.join(\n",
        "                self.base_dir,\n",
        "                pathlib.Path(self.data_file).stem + \"_XLMS_distances_Histplot.jpeg\"\n",
        "            )\n",
        "            plt.savefig(output_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "            print(f\"Histogram created with {len(valid_data)} valid data points\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating histogram: {str(e)}\")\n",
        "            # Create a minimal plot if regular histogram fails\n",
        "            try:\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                plt.text(0.5, 0.5, \"Insufficient data for histogram\",\n",
        "                        ha='center', va='center')\n",
        "                plt.savefig(output_plot_path, dpi=300, bbox_inches='tight')\n",
        "                plt.close()\n",
        "            except Exception as e2:\n",
        "                print(f\"Could not create fallback plot: {str(e2)}\")\n",
        "\n",
        "    def visualize_crosslinks(self, is_manual):\n",
        "        \"\"\"\n",
        "        Generate PyMOL visualization of cross-links.\n",
        "\n",
        "        Args:\n",
        "            is_manual (bool): If True, use manually uploaded structures;\n",
        "                            if False, use AlphaFold structures\n",
        "\n",
        "        Creates:\n",
        "            - Individual PyMOL sessions for each cross-link\n",
        "            - Consolidated views of all cross-links per protein\n",
        "            - Color-coded distance violations (green=satisfied, red=violated)\n",
        "\n",
        "        TODO:\n",
        "        Optimize this\n",
        "        \"\"\"\n",
        "        from pymol import cmd\n",
        "        from pymol.cgo import CYLINDER\n",
        "        if self.is_visualization_allowed and not is_manual:\n",
        "            try:\n",
        "                os.mkdir(os.path.join(self.base_dir ,\"PyMOL Sessions\"))\n",
        "            except:\n",
        "                shutil.rmtree(os.path.join(self.base_dir ,\"PyMOL Sessions\"))\n",
        "                os.mkdir(os.path.join(self.base_dir ,\"PyMOL Sessions\"))\n",
        "            proteins_with_structure = self.XLMS_proteins_with_structure_info\n",
        "\n",
        "        elif self.is_visualization_allowed and is_manual:\n",
        "            try:\n",
        "                os.mkdir(os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\"))\n",
        "                os.chdir(os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\"))\n",
        "            except:\n",
        "                shutil.rmtree(os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\"))\n",
        "                os.mkdir(os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\"))\n",
        "                os.chdir(os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\"))\n",
        "\n",
        "            proteins_with_structure = self.XLMS_cif_files_protein_names\n",
        "        else:\n",
        "            raise Exception(\"Error in flow: visualize_alphfold_crosslinks. Contact Development Team.\")\n",
        "\n",
        "        processed_input = pd.read_csv(os.path.join(self.base_dir, pathlib.Path(self.data_file).stem +'_XLMS_Distances_WO_Duplicates.csv'))\n",
        "\n",
        "        if self.are_manual_structures_verified:\n",
        "            input_for_pymol = processed_input[[\n",
        "                'uniprotID',\n",
        "                'Peptide A',\n",
        "                'Peptide B',\n",
        "                'Absolute Peptide A-Pos',\n",
        "                'Absolute Peptide B-Pos',\n",
        "                'Residue Distance',\n",
        "                'Residue Distance (Manual)',\n",
        "                'Residue 1 Number (Manual)',\n",
        "                'Residue 2 Number (Manual)'\n",
        "            ]]\n",
        "        else:\n",
        "            input_for_pymol = processed_input[[\n",
        "                'uniprotID',\n",
        "                'Peptide A',\n",
        "                'Peptide B',\n",
        "                'Absolute Peptide A-Pos',\n",
        "                'Absolute Peptide B-Pos',\n",
        "                'Residue Distance',\n",
        "            ]]\n",
        "\n",
        "        proteins_processed_counter = {}\n",
        "\n",
        "        for index, row in input_for_pymol.iterrows():\n",
        "            protein = row['uniprotID']\n",
        "            counter = 0\n",
        "\n",
        "            if protein not in proteins_with_structure:\n",
        "                print(f\"Skipped PyMOL Session generation for {protein}. Reason: Structure not found!\")\n",
        "                continue\n",
        "            if is_manual and protein in self.erroneous_XLMS_cif_files_protein_names:\n",
        "                print(f\"Skipped PyMOL Session generation for {protein}. Reason: Structure has a problem!\")\n",
        "                continue\n",
        "\n",
        "            if protein in proteins_processed_counter.keys():\n",
        "                proteins_processed_counter[protein] += 1\n",
        "                counter = proteins_processed_counter[protein]\n",
        "            else:\n",
        "                proteins_processed_counter[protein] = 0\n",
        "                counter = proteins_processed_counter[protein]\n",
        "                if not is_manual:\n",
        "                    os.mkdir(os.path.join(self.base_dir , \"PyMOL Sessions\" , protein))\n",
        "                else:\n",
        "                    os.mkdir(os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\" , protein))\n",
        "\n",
        "            cmd.reinitialize()\n",
        "            if not is_manual:\n",
        "                cmd.load(os.path.join(self.base_dir , 'AlphaFold Structures' , protein , f'{protein}.cif'))\n",
        "            else:\n",
        "                cmd.load(os.path.join(self.base_dir, \"Uploaded Structures\", f'{protein}.cif'))\n",
        "            cmd.spectrum('b', 'rainbow_r')  # approximate AF coloring\n",
        "            cmd.bg_color('white')\n",
        "\n",
        "            colors = {\n",
        "                'green': [0.0, 1.0, 0.0], # green\n",
        "                'red': [0.82, 0.0, 0.3]   # dubnium\n",
        "            }\n",
        "\n",
        "            radius = 0.5\n",
        "            selection = 'all'\n",
        "            atom = 'CA'\n",
        "            prefix = 'xl'\n",
        "            if is_manual:\n",
        "                res_distance = row['Residue Distance']\n",
        "            else:\n",
        "                res_distance = row['Residue Distance']\n",
        "            threshold = self.residue_distance_threshold\n",
        "\n",
        "            if is_manual:\n",
        "                x1, y1, z1 = cmd.get_coords(f'{selection} and resi {int(row[\"Residue 1 Number (Manual)\"])} and name {atom}', 1)[0]\n",
        "                x2, y2, z2 = cmd.get_coords(f'{selection} and resi {int(row[\"Residue 2 Number (Manual)\"])} and name {atom}', 1)[0]\n",
        "\n",
        "                cmd.distance(f'{selection} and resi {row[\"Residue 1 Number (Manual)\"]} and name {atom}', f'{selection} and resi {row[\"Residue 2 Number (Manual)\"]} and name {atom}')\n",
        "            else:\n",
        "                x1, y1, z1 = cmd.get_coords(f'{selection} and resi {int(row[\"Absolute Peptide A-Pos\"])} and name {atom}', 1)[0]\n",
        "                x2, y2, z2 = cmd.get_coords(f'{selection} and resi {int(row[\"Absolute Peptide B-Pos\"])} and name {atom}', 1)[0]\n",
        "\n",
        "                cmd.distance(f'{selection} and resi {row[\"Absolute Peptide A-Pos\"]} and name {atom}', f'{selection} and resi {row[\"Absolute Peptide B-Pos\"]} and name {atom}')\n",
        "\n",
        "            d = np.linalg.norm(np.array([x2, y2, z2]) - np.array([x1, y1, z1]))\n",
        "\n",
        "            if d <= threshold:\n",
        "\n",
        "                r1, g1, b1 = colors['green']\n",
        "                r2, g2, b2 = colors['green']\n",
        "\n",
        "            else:\n",
        "\n",
        "                r1, g1, b1 = colors['red']\n",
        "                r2, g2, b2 = colors['red']\n",
        "\n",
        "            if is_manual:\n",
        "                cmd.load_cgo([CYLINDER, x1, y1, z1, x2, y2, z2, radius, r1, g1, b1, r2, g2, b2],\n",
        "                    f'{prefix}_{row[\"Residue 1 Number (Manual)\"]}_{row[\"Residue 2 Number (Manual)\"]}_{atom}')\n",
        "            else:\n",
        "                cmd.load_cgo([CYLINDER, x1, y1, z1, x2, y2, z2, radius, r1, g1, b1, r2, g2, b2],\n",
        "                    f'{prefix}_{row[\"Absolute Peptide A-Pos\"]}_{row[\"Absolute Peptide B-Pos\"]}_{atom}')\n",
        "\n",
        "            cmd.group(prefix, f'{prefix}_*')\n",
        "            #print(res_distance)\n",
        "            cmd.label(f'{prefix}_*', str(res_distance))\n",
        "            if not is_manual:\n",
        "                cmd.save(os.path.join(self.base_dir , \"PyMOL Sessions\" , protein , f'{protein}-{counter}.pse'))\n",
        "            else:\n",
        "                cmd.save(os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\" , protein , f'{protein}-{counter}.pse'))\n",
        "            if proteins_processed_counter[protein] == 0:\n",
        "                if not is_manual:\n",
        "                    cmd.save(os.path.join(self.base_dir , \"PyMOL Sessions\" , protein , f'{protein}-Consolidated.pse'))\n",
        "                else:\n",
        "                    cmd.save(os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\" , protein , f'{protein}-Consolidated.pse'))\n",
        "            else:\n",
        "                cmd.reinitialize()\n",
        "                if not is_manual:\n",
        "                    cmd.load(os.path.join(self.base_dir , \"PyMOL Sessions\" , protein , f'{protein}-Consolidated.pse'))\n",
        "                else:\n",
        "                    cmd.load(os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\" , protein , f'{protein}-Consolidated.pse'))\n",
        "\n",
        "                if is_manual:\n",
        "                    cmd.distance(f'{selection} and resi {row[\"Residue 1 Number (Manual)\"]} and name {atom}',\n",
        "                                f'{selection} and resi {row[\"Residue 2 Number (Manual)\"]} and name {atom}')\n",
        "                    cmd.load_cgo([CYLINDER, x1, y1, z1, x2, y2, z2, radius, r1, g1, b1, r2, g2, b2],\n",
        "                                f'{prefix}_{row[\"Residue 1 Number (Manual)\"]}_{row[\"Residue 2 Number (Manual)\"]}_{atom}_{counter}')\n",
        "                    cmd.group(prefix, f'{prefix}_*')\n",
        "                    cmd.label(f'{prefix}_*', str(res_distance))\n",
        "                else:\n",
        "                    cmd.distance(f'{selection} and resi {row[\"Absolute Peptide A-Pos\"]} and name {atom}',\n",
        "                                f'{selection} and resi {row[\"Absolute Peptide B-Pos\"]} and name {atom}')\n",
        "                    cmd.load_cgo([CYLINDER, x1, y1, z1, x2, y2, z2, radius, r1, g1, b1, r2, g2, b2],\n",
        "                                f'{prefix}_{row[\"Absolute Peptide A-Pos\"]}_{row[\"Absolute Peptide A-Pos\"]}_{atom}_{counter}')\n",
        "                    cmd.group(prefix, f'{prefix}_*')\n",
        "                    cmd.label(f'{prefix}_*', str(res_distance))\n",
        "                if not is_manual:\n",
        "                    cmd.save(os.path.join(self.base_dir , \"PyMOL Sessions\" , protein , f'{protein}-Consolidated.pse'))\n",
        "                else:\n",
        "                    cmd.save(os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\" , protein , f'{protein}-Consolidated.pse'))\n",
        "            if not is_manual:\n",
        "                print(\"PyMOL Session saved in \" + os.path.join(self.base_dir , \"PyMOL Sessions\" , protein , f'{protein}-{counter}.pse'))\n",
        "            else:\n",
        "                print(\"PyMOL Session saved in \" + os.path.join(self.base_dir, \"Uploaded Structures\", \"PyMOL Sessions\" , protein , f'{protein}-{counter}.pse'))\n",
        "\n",
        "main_obj = AlphaCrossXLBackend()\n",
        "\n",
        "def alphacrossx_logger(log_type, message):\n",
        "    # Implement Logger Functionality\n",
        "    pass\n",
        "\n",
        "def alphacrossxl_main():\n",
        "    # Persistent Header Defined First\n",
        "    app_title = 'AlphaCross-XL (Colab Version)'\n",
        "    app_version_number = 'v1.0'\n",
        "    app_update_date = 'Jan 6, 2025'\n",
        "    app_info = 'Python-based Interactive Tool for Analyzing XL-MS Data-sets and creating useful visualizations.'\n",
        "\n",
        "    app_header_html = widgets.HTML(value=\n",
        "    f\"\"\"\n",
        "    <div style='margin:10px'>\n",
        "    <h1 style='text-align: center;'>{app_title}</h1>\n",
        "    <h5 style='text-align: center;'>{app_info}</h5>\n",
        "    <hr>\n",
        "    <h3><span style='text-align: left;'>Version: {app_version_number}</span><span style='float: right;'>Last Updated on: {app_update_date}</span></h3>\n",
        "    <hr>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    )\n",
        "    # Aligning Widgets StackOverFlow Reference: https://stackoverflow.com/a/62760915\n",
        "    centered_box_layout_visible = widgets.Layout(display='flex',\n",
        "                    flex_flow='column',\n",
        "                    align_items='center',\n",
        "                    #width='50%'\n",
        "                    )\n",
        "    left_aligned_box_layout_visible = widgets.Layout(display='flex',\n",
        "                    flex_flow='column',\n",
        "                    align_items='flex-start',\n",
        "                    #width='50%'\n",
        "                    )\n",
        "    right_aligned_box_layout_visible = widgets.Layout(display='flex',\n",
        "                    flex_flow='column',\n",
        "                    align_items='flex-end',\n",
        "                    #width='50%'\n",
        "                    )\n",
        "\n",
        "    # Loading Bar Stuff\n",
        "    # taken from https://stackoverflow.com/a/62889861\n",
        "    loading_bar_path = os.path.join(main_base_dir, 'loading-bar.gif')\n",
        "    loading_bar_url = 'https://drive.usercontent.google.com/uc?id=1319Us_Vh57iYmBVPdwg-Sk4SVcfdPzQS'\n",
        "    try:\n",
        "        with open(loading_bar_path, 'rb') as f:\n",
        "            img = f.read()\n",
        "    except:\n",
        "        with open(loading_bar_path, 'wb') as f:\n",
        "            f.write(requests.get(loading_bar_url).content)\n",
        "        with open(loading_bar_path, 'rb') as f:\n",
        "            img = f.read()\n",
        "\n",
        "\n",
        "\n",
        "    #   create loading bar widget, ready to display when running long function\n",
        "    loading_bar = widgets.Image(value=img, layout=Layout(max_height='40px'))\n",
        "    centered_loading_bar = widgets.VBox([loading_bar], layout=centered_box_layout_visible)\n",
        "\n",
        "    # Output Defined Now but will be displayed just before Footer as persistent widget.\n",
        "    output_widget = widgets.Output(layout=Layout(overflow='scroll visible',\n",
        "                                        #border='3px solid black',\n",
        "                                        width='',\n",
        "                                        max_height='200px',\n",
        "                                        flex_flow='column',\n",
        "                                        display='flex'))\n",
        "\n",
        "    # Persistent Header (Would Show during all pages.)\n",
        "    display(app_header_html)\n",
        "\n",
        "    # Widgets\n",
        "    ## Page 1 Widgets\n",
        "    button_start_app = widgets.Button(description=\"AlphaCross-XL is Initializing. Please Wait.\",\n",
        "                                      layout=Layout(\n",
        "                                          width='auto',\n",
        "                                      ),\n",
        "                                      disabled=True)\n",
        "    page_start_app = widgets.VBox(children=[button_start_app],layout=centered_box_layout_visible)\n",
        "\n",
        "\n",
        "    ## Page 2 Widgets\n",
        "    file_upload_data_widget = widgets.FileUpload(\n",
        "        description='XL-MS Input File',\n",
        "        accept='.csv, .xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
        "        multiple=False,\n",
        "        layout={'width': 'auto'}\n",
        "    )\n",
        "    file_upload_fasta_db_widget = widgets.FileUpload(\n",
        "        description='FASTA Database',\n",
        "        accept='.gz',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
        "        multiple=False,\n",
        "        layout={'width': 'auto'}\n",
        "    )\n",
        "    labelled_file_upload_data_widget = widgets.HBox(children=[widgets.Label(value=\"Please Input the XL-MS Data Set (Only .CSV/.XLSX Files Allowed): \"), file_upload_data_widget]\n",
        "                                                    ) #layout none required?\n",
        "    labelled_file_upload_fasta_db_widget = widgets.HBox(children=[widgets.Label(value=\"Please Input the compressed FASTA Database (Only .FASTA.GZ Files Allowed): \"), file_upload_fasta_db_widget]\n",
        "                                                    ) #layout none required?\n",
        "    button_submit_files = widgets.Button(description=\"Submit Files\")\n",
        "    centered_button_submit_files = widgets.VBox(children=[button_submit_files], layout=centered_box_layout_visible)\n",
        "\n",
        "    page_input_files = widgets.VBox(children=[labelled_file_upload_data_widget, labelled_file_upload_fasta_db_widget, centered_button_submit_files], layout={'display': 'none'})\n",
        "\n",
        "    ## Page 3 Widgets\n",
        "    button_confirm_files = widgets.Button(description=\"Confirm Files\")\n",
        "    button_cancel_files = widgets.Button(description=\"Cancel Upload\")\n",
        "\n",
        "    page_confirm_or_cancel_files = widgets.VBox(children=[button_confirm_files, button_cancel_files], layout={'display': 'none'})\n",
        "\n",
        "    ## Page 4 Widgets\n",
        "    dropdown_uniprot_id = widgets.Dropdown(\n",
        "        options=['Options not initialized'],\n",
        "        description='Choose UniProt ID Column',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': 'max-content'}\n",
        "    )\n",
        "    dropdown_xlink_types = widgets.Dropdown(\n",
        "        options=['Options not initialized'],\n",
        "        description='Choose Cross-Link Type Column',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': 'max-content'}\n",
        "    )\n",
        "    dropdown_peptide_a = widgets.Dropdown(\n",
        "        options=['Options not initialized'],\n",
        "        description='Choose Peptide A Column',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': 'max-content'}\n",
        "    )\n",
        "    dropdown_peptide_b = widgets.Dropdown(\n",
        "        options=['Options not initialized'],\n",
        "        description='Choose Peptide B Column',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': 'max-content'}\n",
        "    )\n",
        "    dropdown_link_site_a = widgets.Dropdown(\n",
        "        options=['Options not initialized'],\n",
        "        description='Choose Link Site A Column',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': 'max-content'}\n",
        "    )\n",
        "    dropdown_link_site_b = widgets.Dropdown(\n",
        "        options=['Options not initialized'],\n",
        "        description='Choose Link Site B Column',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': 'max-content'}\n",
        "    )\n",
        "\n",
        "\n",
        "    button_confirm_columns = widgets.Button(description=\"Confirm Input Columns\", layout={'width': 'auto'})\n",
        "    button_go_back_columns = widgets.Button(description=\"Go Back\", layout={'width': 'auto'})\n",
        "\n",
        "    buttons_input_columns = widgets.HBox(children=[button_confirm_columns, button_go_back_columns])\n",
        "    #centered_button_confirm_columns = widgets.VBox(children=[button_confirm_columns], layout=centered_box_layout_visible)\n",
        "    page_input_columns = widgets.VBox(children=[dropdown_uniprot_id, dropdown_xlink_types, dropdown_peptide_a, dropdown_peptide_b, dropdown_link_site_a, dropdown_link_site_b, buttons_input_columns], layout={'display': 'none'})\n",
        "\n",
        "\n",
        "    ## Page 5 Widgets\n",
        "    inttext_threshold_dist = widgets.BoundedIntText(\n",
        "        value=20,\n",
        "        min=1,\n",
        "        max=100,\n",
        "        step=1,\n",
        "        description='Threshold Distance (in Angstroms, Min - 1, Max - 100):',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': 'initial'}\n",
        "    )\n",
        "    dropdown_xlink_type = widgets.Dropdown(\n",
        "        options=['Options not initialized'],\n",
        "        description='Choose Cross-Link Type for Analysis',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': 'max-content'}\n",
        "    )\n",
        "    button_confirm_analysis_options = widgets.Button(description=\"Confirm Options\", layout={'width': 'auto'})\n",
        "    button_go_back_analysis_options = widgets.Button(description=\"Go Back\", layout={'width': 'auto'})\n",
        "\n",
        "    buttons_analysis_options = widgets.HBox(children=[button_confirm_analysis_options, button_go_back_analysis_options])\n",
        "    #centered_button_confirm_analysis_options = widgets.VBox(children=[button_confirm_analysis_options], layout=centered_box_layout_visible)\n",
        "    page_analysis_options = widgets.VBox(children=[inttext_threshold_dist, dropdown_xlink_type, buttons_analysis_options], layout={'display': 'none'})\n",
        "\n",
        "    ## Page 6 Widgets\n",
        "    radiobutton_visualization = widgets.RadioButtons(\n",
        "        options=['Yes', 'No'],\n",
        "        value='Yes',\n",
        "        description='Do you want to generate PyMOL Visualizations: ',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': 'max-content'}\n",
        "    )\n",
        "    radiobutton_manual_comparison = widgets.RadioButtons(\n",
        "        options=['Yes', 'No'],\n",
        "        value='No',\n",
        "        description='Do you want to upload your own protein structures for comparison: ',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': 'max-content'}\n",
        "    )\n",
        "    file_upload_protein_structure_widget = widgets.FileUpload(\n",
        "        description='Structure Files',\n",
        "        accept='.zip',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
        "        multiple=False,\n",
        "        disabled=True,\n",
        "    )\n",
        "    labelled_file_upload_protein_structure_widget = widgets.HBox(children=[widgets.Label(value=\"Please Input your own Protein Structure Files (.cif only) in a .ZIP Archive: \"), file_upload_protein_structure_widget]\n",
        "                                                                )\n",
        "\n",
        "    button_confirm_visualization_options = widgets.Button(description=\"Confirm Visualization Options\", layout={'width': 'auto'})\n",
        "    button_go_back_visualization_options = widgets.Button(description=\"Go Back\", layout={'width': 'auto'})\n",
        "\n",
        "    buttons_visualization_options = widgets.HBox(children=[button_confirm_visualization_options, button_go_back_visualization_options])\n",
        "    #centered_button_confirm_visualization_options = widgets.VBox(children=[button_confirm_visualization_options], layout=centered_box_layout_visible)\n",
        "    page_visualization_options = widgets.VBox(children=[radiobutton_visualization, radiobutton_manual_comparison, labelled_file_upload_protein_structure_widget, buttons_visualization_options], layout={'display': 'none'})\n",
        "\n",
        "    ## Page 7 Widgets - Processing Confirm\n",
        "    button_preview = widgets.Button(description=\"Start Analysis\", layout={'width': 'auto'})\n",
        "    button_go_back_preview = widgets.Button(description=\"Go Back\", layout={'width': 'auto'})\n",
        "    buttons_preview = widgets.HBox(children=[button_preview, button_go_back_preview])\n",
        "\n",
        "    page_preview = widgets.VBox(\n",
        "        children=[\n",
        "            file_upload_data_widget,\n",
        "            file_upload_fasta_db_widget,\n",
        "            dropdown_uniprot_id,\n",
        "            dropdown_xlink_types,\n",
        "            dropdown_peptide_a,\n",
        "            dropdown_peptide_b,\n",
        "            dropdown_link_site_a,\n",
        "            dropdown_link_site_b,\n",
        "            inttext_threshold_dist,\n",
        "            dropdown_xlink_type,\n",
        "            radiobutton_visualization,\n",
        "            radiobutton_manual_comparison,\n",
        "            file_upload_protein_structure_widget,\n",
        "            buttons_preview\n",
        "        ],\n",
        "        layout={'display': 'none'}\n",
        "    )\n",
        "    ## Page 8 Widgets\n",
        "    page_result = widgets.HTML(value=\n",
        "    \"\"\"\n",
        "    <div style='margin:10px'>\n",
        "    <button>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # Display Sequence\n",
        "    ## Page 1 Display Sequence\n",
        "    display(page_start_app)\n",
        "\n",
        "    ## Page 2 Display Sequence\n",
        "    display(page_input_files)\n",
        "\n",
        "    ## Page 3 Display Sequence\n",
        "    display(page_confirm_or_cancel_files)\n",
        "\n",
        "    ## Page 4 Display Sequence\n",
        "    display(page_input_columns)\n",
        "\n",
        "    ## Page 5 Display Sequence\n",
        "    display(page_analysis_options)\n",
        "\n",
        "    ## Page 6 Display Sequence\n",
        "    display(page_visualization_options)\n",
        "\n",
        "    ## Page 7 Display Sequence\n",
        "    #display(page_preview)\n",
        "    display(page_preview)\n",
        "\n",
        "    # ..\n",
        "\n",
        "\n",
        "    # Widget Handler Functions\n",
        "    ## Page 1 Widget Handler Functions\n",
        "    def on_click_button_reset(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            # Clear All Files.\n",
        "            # Get back to Start Page.\n",
        "            print('Resetting AlphaCross-XL.')\n",
        "\n",
        "    def on_click_button_start(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            page_start_app.layout.display = 'none'\n",
        "            page_input_files.layout.display = 'block'\n",
        "            centered_button_submit_files.layout = {'display': 'flex', 'flex_flow':'column',\n",
        "                    'align_items': 'center'}\n",
        "            print(\"Started. Awaiting Files.\")\n",
        "\n",
        "    ## Page 2 Widget Handler Functions\n",
        "    def on_click_button_submit_files(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            print('Verifying Submitted Files.')\n",
        "            if file_upload_data_widget.value and file_upload_fasta_db_widget.value:\n",
        "                page_input_files.layout.display = 'none'\n",
        "                page_confirm_or_cancel_files.layout = {'display': 'flex', 'flex_flow':'column',\n",
        "                    'align_items': 'center'}\n",
        "\n",
        "                data_filename, data_content = next(iter(file_upload_data_widget.value.items()))\n",
        "                print(\"Data File: \", data_filename)\n",
        "                db_filename, db_content = next(iter(file_upload_fasta_db_widget.value.items()))\n",
        "                print(\"Database File: \", db_filename)\n",
        "\n",
        "                print(\"Make sure your data file is of correct format and FASTA Database is of correct species.\")\n",
        "                print(\"If selected files are correct, press confirm to continue.\")\n",
        "\n",
        "            else:\n",
        "                clear_output()\n",
        "                print(\"Please upload both input files together. Try again\")\n",
        "\n",
        "    ## Page 3 Widget Handler Functions\n",
        "    def on_click_button_confirm_files(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            os.chdir(main_base_dir)\n",
        "            main_obj.base_dir = os.getcwd()\n",
        "            main_obj.base_dir_parent = main_base_dir_parent\n",
        "            #print(\"BASE DIRRRR\", base_dir)\n",
        "            #main_obj = AlphaCrossXL(base_dir)\n",
        "            page_confirm_or_cancel_files.layout.display = 'none'\n",
        "            print('Files Confirmed. Uploading Files.')\n",
        "            data_filename, data_content = next(iter(file_upload_data_widget.value.items()))\n",
        "            print(\"Data File: \", data_filename)\n",
        "            db_filename, db_content = next(iter(file_upload_fasta_db_widget.value.items()))\n",
        "            print(\"Database File: \",db_filename)\n",
        "\n",
        "            data_file_path = os.path.join(main_obj.base_dir, data_filename)\n",
        "            db_path = os.path.join(main_obj.base_dir, db_filename)\n",
        "\n",
        "            with open(data_file_path, 'wb') as f:\n",
        "                f.write(data_content['content'])\n",
        "            with open(db_path, 'wb') as f:\n",
        "                f.write(db_content['content'])\n",
        "\n",
        "            if os.path.exists(data_file_path) and os.path.exists(db_path):\n",
        "                print(\"Files saved successfully. Proceeding to Column Selection.\")\n",
        "            else:\n",
        "                raise Exception(\"Failed to save files. Contact Developer Team.\")\n",
        "\n",
        "            main_obj.data_file = data_file_path\n",
        "            main_obj.fasta_db = db_path\n",
        "            main_obj.initialize_input_file()\n",
        "            main_obj.process_fasta()\n",
        "            input_file_columns = main_obj.get_input_file_columns()\n",
        "            #input_x_link_types = main_obj.get_input_xlink_types()\n",
        "            print(\"Input File Columns: \", input_file_columns)\n",
        "            print(\"Please choose corresponding columns in input file.\")\n",
        "\n",
        "            dropdown_uniprot_id.options = input_file_columns\n",
        "            dropdown_xlink_types.options = input_file_columns\n",
        "            dropdown_peptide_a.options = input_file_columns\n",
        "            dropdown_peptide_b.options = input_file_columns\n",
        "            dropdown_link_site_a.options = input_file_columns\n",
        "            dropdown_link_site_b.options = input_file_columns\n",
        "\n",
        "            #main_obj.threshold_dist = inttext_threshold_dist.value\n",
        "            #print(f\"Upload Process completed. Saved input files to {base_dir}.\")\n",
        "            #print(\"You can find the files at /content\")\n",
        "            page_input_columns.layout = {'display': 'flex', 'flex_flow':'column',\n",
        "                    'align_items': 'center'}\n",
        "\n",
        "\n",
        "    def on_click_button_cancel_files(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            print('Canceled Operation. Please Start Again.')\n",
        "\n",
        "            # Easy Fix for Faulty File Counter in ipywidgets 7.7.1\n",
        "            file_upload_data_widget._counter = 0\n",
        "            file_upload_data_widget.value.clear()\n",
        "            file_upload_fasta_db_widget._counter = 0\n",
        "            file_upload_fasta_db_widget.value.clear()\n",
        "\n",
        "            page_confirm_or_cancel_files.layout.display = 'none'\n",
        "            page_input_files.layout.display = 'block'\n",
        "\n",
        "    ## Page 4 Widget Handler Functions\n",
        "    def on_click_button_confirm_columns(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            user_chosen_columns_dict = {\n",
        "                \"uniprotID\": dropdown_uniprot_id.value,\n",
        "                \"X-link type\": dropdown_xlink_types.value,\n",
        "                \"Peptide A\": dropdown_peptide_a.value,\n",
        "                \"Residue 1\": dropdown_link_site_a.value,\n",
        "                \"Residue 2\": dropdown_link_site_b.value,\n",
        "                \"Peptide B\": dropdown_peptide_b.value,\n",
        "            }\n",
        "            if (len(user_chosen_columns_dict.values()) != len(set(user_chosen_columns_dict.values()))):\n",
        "                print(\"You have chosen the same columns for one particular column type.\")\n",
        "                print(\"Please choose unique columns for each type.\")\n",
        "            else:\n",
        "                print(\"Columns are Verified\")\n",
        "                main_obj.set_input_file_columns(user_chosen_columns_dict=user_chosen_columns_dict, reset=False)\n",
        "                page_input_columns.layout.display = 'none'\n",
        "                dropdown_xlink_type.options = main_obj.get_input_xlink_types()\n",
        "                page_analysis_options.layout = {'display': 'flex', 'flex_flow':'column',\n",
        "                        'align_items': 'center'}\n",
        "                print('Input Columns Confirmed. Proceeding to Analysis Options.')\n",
        "                print(\"Please choose analysis options.\")\n",
        "\n",
        "\n",
        "\n",
        "    def on_click_button_go_back_columns(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            # Deleting Submitted Files to Preserve Memory\n",
        "            current_data_file_path = main_obj.data_file\n",
        "            current_fasta_db_path = main_obj.fasta_db\n",
        "            os.remove(current_data_file_path)\n",
        "            os.remove(current_fasta_db_path)\n",
        "            os.remove(main_obj.fasta_db + '.fxi') #pyfastx index file\n",
        "\n",
        "            # Resetting Main Object\n",
        "            main_obj.__init__()\n",
        "            print('Canceled Operation. Please Start Again.')\n",
        "\n",
        "            # Easy Fix for Faulty File Counter in ipywidgets 7.7.1\n",
        "            file_upload_data_widget._counter = 0\n",
        "            file_upload_data_widget.value.clear()\n",
        "            file_upload_fasta_db_widget._counter = 0\n",
        "            file_upload_fasta_db_widget.value.clear()\n",
        "\n",
        "            dropdown_uniprot_id.options = ['Options not initialized']\n",
        "            dropdown_xlink_types.options = ['Options not initialized']\n",
        "            dropdown_peptide_a.options = ['Options not initialized']\n",
        "            dropdown_peptide_b.options = ['Options not initialized']\n",
        "            dropdown_link_site_a.options = ['Options not initialized']\n",
        "            dropdown_link_site_b.options = ['Options not initialized']\n",
        "\n",
        "            page_input_columns.layout.display = 'none'\n",
        "            page_input_files.layout.display = 'block'\n",
        "\n",
        "\n",
        "    ## Page 5 Widget Handler Functions\n",
        "    def on_click_button_confirm_analysis_options(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            main_obj.set_input_xlink_type_threshold_dist(\n",
        "                user_x_link_type_chosen=dropdown_xlink_type.value,\n",
        "                user_threshold_dist_chosen=inttext_threshold_dist.value\n",
        "            )\n",
        "            page_analysis_options.layout.display = 'none'\n",
        "            print(\"Analysis Options Confirmed. Proceeding to Visualization Options.\")\n",
        "            page_visualization_options.layout = {'display': 'flex', 'flex_flow':'column',\n",
        "                    'align_items': 'center'}\n",
        "\n",
        "            print(\"Please choose visualization options.\")\n",
        "\n",
        "    def on_click_button_go_back_analysis_options(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "\n",
        "            user_chosen_columns_dict = {\n",
        "                \"uniprotID\": None,\n",
        "                \"X-link type\": None,\n",
        "                \"Peptide A\": None,\n",
        "                \"Residue 1\": None,\n",
        "                \"Residue 2\": None,\n",
        "                \"Peptide B\": None,\n",
        "            }\n",
        "            main_obj.set_input_file_columns(user_chosen_columns_dict=user_chosen_columns_dict, reset=True)\n",
        "            page_analysis_options.layout.display = 'none'\n",
        "            page_input_columns.layout = {'display': 'flex', 'flex_flow':'column',\n",
        "                    'align_items': 'center'}\n",
        "            dropdown_xlink_type.options = ['Options not initialized']\n",
        "\n",
        "\n",
        "\n",
        "    ## Page 6 Widget Handler Functions\n",
        "    def on_click_button_confirm_visualization_options(b):\n",
        "\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            if radiobutton_manual_comparison.value == 'Yes' and file_upload_protein_structure_widget.value == {}:\n",
        "                print('Please upload the .cif files in a single .zip archive.')\n",
        "                #print('Make sure your .cif files are labelled as per format: {UniProt_ID}.cif\n",
        "            else:\n",
        "                if radiobutton_visualization.value == 'Yes':\n",
        "                    main_obj.is_visualization_allowed = True\n",
        "                else:\n",
        "                    main_obj.is_visualization_allowed = False\n",
        "                if radiobutton_manual_comparison.value == 'Yes':\n",
        "                    main_obj.is_manual_protein_struct = True\n",
        "                else:\n",
        "                    main_obj.is_manual_protein_struct = False\n",
        "\n",
        "                if main_obj.is_manual_protein_struct:\n",
        "                    protein_struct_filename, protein_struct_content = next(iter(file_upload_protein_structure_widget.value.items()))\n",
        "                    print(\"Protein Structures Archive Uploaded: \", protein_struct_filename)\n",
        "                    protein_struct_path = os.path.join(main_obj.base_dir, protein_struct_filename)\n",
        "                    main_obj.manual_protein_struct_file = protein_struct_path\n",
        "                    with open(protein_struct_path, 'wb') as f:\n",
        "                        f.write(protein_struct_content['content'])\n",
        "                    main_obj.verify_and_process_manual_protein_struct_file()\n",
        "                print(\"Visualization Options Confirmed. Proceeding to Final Preview.\")\n",
        "                page_visualization_options.layout.display = 'none'\n",
        "                file_upload_data_widget.disabled = True\n",
        "                file_upload_fasta_db_widget.disabled = True\n",
        "                dropdown_uniprot_id.disabled = True\n",
        "                dropdown_xlink_types.disabled = True\n",
        "                dropdown_peptide_a.disabled = True\n",
        "                dropdown_peptide_b.disabled = True\n",
        "                dropdown_link_site_a.disabled = True\n",
        "                dropdown_link_site_b.disabled = True\n",
        "                inttext_threshold_dist.disabled = True\n",
        "                dropdown_xlink_type.disabled = True\n",
        "                radiobutton_visualization.disabled = True\n",
        "                radiobutton_manual_comparison.disabled = True\n",
        "                file_upload_protein_structure_widget.disabled = True\n",
        "                page_preview.layout = {'display': 'flex', 'flex_flow':'column',\n",
        "                        'align_items': 'center'}\n",
        "\n",
        "\n",
        "    def on_click_button_go_back_visualization_options(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            main_obj.set_input_xlink_type_threshold_dist(\n",
        "                user_x_link_type_chosen=None,\n",
        "                user_threshold_dist_chosen=None,\n",
        "                reset=True\n",
        "            )\n",
        "\n",
        "            page_visualization_options.layout.display = 'none'\n",
        "            page_analysis_options.layout = {'display': 'flex', 'flex_flow':'column',\n",
        "                    'align_items': 'center'}\n",
        "\n",
        "    def on_change_radiobutton_manual_comparison(change):\n",
        "        with output_widget:\n",
        "            if change['new'] == 'Yes':\n",
        "                file_upload_protein_structure_widget.disabled = False\n",
        "                print(\"Please upload your .cif structure files in a single .zip archive.\")\n",
        "                print(\"Make sure your .cif files are labelled as per format: {UniProt_ID}.cif\")\n",
        "                print(\"Incorrectly named files will be ignored.\")\n",
        "            else:\n",
        "                file_upload_protein_structure_widget.disabled = True\n",
        "                file_upload_protein_structure_widget.value.clear()\n",
        "                file_upload_protein_structure_widget._counter = 0\n",
        "\n",
        "    ## Page 7 Widget Handler Functions\n",
        "    def on_click_button_go_back_preview(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            print(\"All parameters have been confirmed. Analysis will now begin.\")\n",
        "            page_preview.layout.display = 'none'\n",
        "            if main_obj.is_manual_protein_struct:\n",
        "                main_obj.verify_and_process_manual_protein_struct_file(reset=True)\n",
        "\n",
        "            page_visualization_options.layout.display = 'none'\n",
        "            file_upload_data_widget.disabled = False\n",
        "            file_upload_fasta_db_widget.disabled = False\n",
        "            dropdown_uniprot_id.disabled = False\n",
        "            dropdown_xlink_types.disabled = False\n",
        "            dropdown_peptide_a.disabled = False\n",
        "            dropdown_peptide_b.disabled = False\n",
        "            dropdown_link_site_a.disabled = False\n",
        "            dropdown_link_site_b.disabled = False\n",
        "            inttext_threshold_dist.disabled = False\n",
        "            dropdown_xlink_type.disabled = False\n",
        "            radiobutton_visualization.disabled = False\n",
        "            radiobutton_manual_comparison.disabled = False\n",
        "            file_upload_protein_structure_widget.disabled = False\n",
        "\n",
        "            page_visualization_options.layout = {'display': 'flex', 'flex_flow':'column',\n",
        "                    'align_items': 'center'}\n",
        "\n",
        "    def on_click_button_preview(b):\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            display(centered_loading_bar)\n",
        "            page_preview.layout.display = 'none'\n",
        "\n",
        "            print(\"Confirmed all parameters. Starting Analysis! Please Wait...\")\n",
        "\n",
        "            main_obj.convert_to_xlms_format()\n",
        "            clear_output()\n",
        "            display(centered_loading_bar)\n",
        "            print(\"Converted to suitable formats.\")\n",
        "            # will have to modify this for protein centric\n",
        "            main_obj.calculate_absolute_chain_pos()\n",
        "            # will have to modify this for protein centric\n",
        "            clear_output()\n",
        "            display(centered_loading_bar)\n",
        "            print(\"Obtained Absolute Positions of Link-Sites in Protein Chain.\")\n",
        "            main_obj.proteins_from_alphafold()\n",
        "            clear_output()\n",
        "            display(centered_loading_bar)\n",
        "            print(\"Downloaded Protein Structures from AlphaFold\")\n",
        "            main_obj.calculate_residue_distance_and_betas_all()\n",
        "            clear_output()\n",
        "            display(centered_loading_bar)\n",
        "            print(\"Computed Residue Distance and extracting pLDDT.\")\n",
        "            main_obj.insert_values_for_duplicates()\n",
        "            clear_output()\n",
        "            display(centered_loading_bar)\n",
        "            print(\"Inserted values for duplicates.\")\n",
        "            main_obj.output_distances()\n",
        "            clear_output()\n",
        "            display(centered_loading_bar)\n",
        "            print(\"Created Output Files\")\n",
        "            main_obj.save_barplot()\n",
        "            main_obj.save_histplot()\n",
        "            clear_output()\n",
        "            display(centered_loading_bar)\n",
        "            print(\"Created Plots\")\n",
        "            if main_obj.is_visualization_allowed and main_obj.is_manual_protein_struct:\n",
        "                main_obj.visualize_crosslinks(is_manual=True)\n",
        "                main_obj.visualize_crosslinks(is_manual=False)\n",
        "                clear_output()\n",
        "                display(centered_loading_bar)\n",
        "                print(\"Visualized Crosslinks (Both AlphaFold and Uploaded Structures)\")\n",
        "            elif main_obj.is_visualization_allowed and not main_obj.is_manual_protein_struct:\n",
        "                main_obj.visualize_crosslinks(is_manual=False)\n",
        "                clear_output()\n",
        "                display(centered_loading_bar)\n",
        "                print(\"Visualized Crosslinks (AlphaFold Only)\")\n",
        "            else:\n",
        "                print(\"No Crosslinks Visualized.\")\n",
        "\n",
        "            print(\"Analysis Complete!\")\n",
        "            print(\"Compressing all analysis files into a .zip archive. Please wait...\")\n",
        "\n",
        "\n",
        "            os.chdir(main_obj.base_dir)\n",
        "            date_string = datetime.date.today().strftime('%Y-%m-%d')\n",
        "            data_filename = '-' + main_obj.data_file.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "            if main_obj.are_manual_structures_verified:\n",
        "                shutil.make_archive(\n",
        "                    'acxl-uploaded_structs-data',\n",
        "                    'zip',\n",
        "                    os.path.join(main_obj.base_dir, 'Uploaded Structures')\n",
        "                )\n",
        "                shutil.rmtree(os.path.join(main_obj.base_dir, 'Uploaded Structures'))\n",
        "            if main_obj.is_visualization_allowed:\n",
        "                shutil.make_archive('acxl-alphafold-pymol-sessions', 'zip', os.path.join(main_obj.base_dir, 'PyMOL Sessions'))\n",
        "                shutil.rmtree(os.path.join(main_obj.base_dir, 'PyMOL Sessions'))\n",
        "\n",
        "            shutil.make_archive(\n",
        "                'acxl-alphafold-structures',\n",
        "                'zip',\n",
        "                os.path.join(main_obj.base_dir, 'AlphaFold Structures')\n",
        "            )\n",
        "            shutil.rmtree(os.path.join(main_obj.base_dir, 'AlphaFold Structures'))\n",
        "            os.remove(os.path.join(main_obj.base_dir, 'loading-bar.gif'))\n",
        "            os.chdir(main_obj.base_dir_parent)\n",
        "            shutil.make_archive(\n",
        "                'acxl-results-'+ date_string + data_filename,\n",
        "                'zip',\n",
        "                main_obj.base_dir\n",
        "            )\n",
        "            result_file_path = os.path.join(main_obj.base_dir_parent, 'acxl-results-'+ date_string + data_filename + '.zip')\n",
        "            clear_output()\n",
        "            print(\"Results are stored in: \",result_file_path)\n",
        "            print(\"Thank you for using AlphaCross-XL!\")\n",
        "            print(\"Downloading Results!\")\n",
        "            print(\"Note: If the download doesn't start automatically, you can download the file manually.\")\n",
        "            print(\"Note: Click the Folder Icon on the RHS Tool bar to see the directory structure.\")\n",
        "            print(\"This may take upto 5-10 if Cross-Links are visualized!\")\n",
        "            print(\"To run the tool again, run this cell again by using the play button or Ctrl/Cmd + Enter\")\n",
        "            files.download(result_file_path)\n",
        "\n",
        "    # Widget-Handler Bindings\n",
        "    ## Page 1 Widget-Handler Bindings\n",
        "    button_start_app.on_click(on_click_button_start)\n",
        "\n",
        "    ## Page 2\n",
        "    button_submit_files.on_click(on_click_button_submit_files)\n",
        "\n",
        "    ## Page 3\n",
        "    button_cancel_files.on_click(on_click_button_cancel_files)\n",
        "    button_confirm_files.on_click(on_click_button_confirm_files)\n",
        "\n",
        "    ## Page 4\n",
        "    button_confirm_columns.on_click(on_click_button_confirm_columns)\n",
        "    button_go_back_columns.on_click(on_click_button_go_back_columns)\n",
        "\n",
        "    ## Page 5\n",
        "    button_confirm_analysis_options.on_click(on_click_button_confirm_analysis_options)\n",
        "    button_go_back_analysis_options.on_click(on_click_button_go_back_analysis_options)\n",
        "\n",
        "    ## Page 6\n",
        "    button_confirm_visualization_options.on_click(on_click_button_confirm_visualization_options)\n",
        "    button_go_back_visualization_options.on_click(on_click_button_go_back_visualization_options)\n",
        "    #radiobutton_visualization.observe(on_change_radiobutton_visualization, names='value')\n",
        "    radiobutton_manual_comparison.observe(on_change_radiobutton_manual_comparison, names='value')\n",
        "\n",
        "    ## Page 7\n",
        "    button_go_back_preview.on_click(on_click_button_go_back_preview)\n",
        "    button_preview.on_click(on_click_button_preview)\n",
        "\n",
        "    ## Page 8\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Processing Functions and Function Calls\n",
        "    ## Page 1 Processing Functions and Function Calls\n",
        "    def update_tool_status_idle():\n",
        "        with output_widget:\n",
        "            clear_output()\n",
        "            print(\"Idle\")\n",
        "    update_tool_status_idle()\n",
        "\n",
        "    # Formatted Output Widget\n",
        "    arranged_output = widgets.VBox(children=[widgets.HTML(\n",
        "                                        value='''<hr><h3 style='text-align: center;'>Console Log (Scroll for Long Outputs)</h3>'''\n",
        "                                    ), output_widget,]\n",
        "\n",
        "                                   )\n",
        "    # Persistent Footer Defined Last\n",
        "    app_credits = '© 2024-2025 AlphaCross-XL Development Team.<br>This tool was developed as a collaborative project at Proteomics Lab, IIT Bombay and Wiita Lab, UCSF, with assistance from Sali Lab, UCSF.'\n",
        "    app_footer = widgets.HTML(value=\n",
        "    f\"\"\"\n",
        "    <div style='margin:0px'>\n",
        "    <hr>\n",
        "    <h5 style='text-align: center;'>{app_credits}</h5>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    display(arranged_output, app_footer)\n",
        "\n",
        "    # Most Important Function which needs to be run once window is rendered\n",
        "    def configure_dependencies():\n",
        "        with output_widget:\n",
        "            try:\n",
        "                clear_output()\n",
        "                print(\"Configuring Dependencies.\")\n",
        "                import prody, pymol\n",
        "                import pyfastx as pyfx\n",
        "                print(\"Dependencies Configured!\")\n",
        "                print(pymol.get_version_message())\n",
        "                print(\"ProDy Version: \", prody.__version__, \", PyFastX Version: \", pyfx.__version__)\n",
        "                button_start_app.description = \"Click Here to Start AlphaCross-XL\"\n",
        "                button_start_app.disabled = False\n",
        "                print(\"AlphaCross-XL is Initialized!\")\n",
        "                print(\"Base Directory: \", main_base_dir)\n",
        "\n",
        "                #update_tool_status_idle()\n",
        "            except:\n",
        "                #print('time taken to run:',t2-t1)\n",
        "                button_start_app.description = \"AlphaCross-XL is Initializing for the First Time. Please Wait upto 10 Minutes.\"\n",
        "                clear_output()\n",
        "                display(centered_loading_bar)\n",
        "                print(\"ProDy and PyFastx are being installed! Please be patient. This takes 1-2 Minutes!\")\n",
        "                try:\n",
        "                    start_time = time.perf_counter()\n",
        "                    !pip install biopython==1.79 pyfastx\n",
        "                    !pip install --no-deps prody\n",
        "                    check_time = time.perf_counter()\n",
        "                    clear_output()\n",
        "                    display(centered_loading_bar)\n",
        "                    print(\"Time taken to install ProDy, PyFastx: \", str(datetime.timedelta(seconds=int(check_time - start_time))))\n",
        "                    print(\"Installing PyMOL. This will take 6-8 Minutes! Do not close the window.\")\n",
        "                    !apt-get install -yq git build-essential python3-dev libglew-dev \\\n",
        "                    libpng-dev libfreetype6-dev libxml2-dev \\\n",
        "                    libmsgpack-dev python3-pyqt5.qtopengl libglm-dev libnetcdf-dev\n",
        "\n",
        "                    clear_output()\n",
        "                    display(centered_loading_bar)\n",
        "                    check_time = time.perf_counter()\n",
        "                    print(\"Time Elapsed: \", str(datetime.timedelta(seconds=int(check_time - start_time))),\" minutes.\")\n",
        "                    print(\"Building PyMOL\")\n",
        "\n",
        "                    # Improvement Idea\n",
        "                    # Download tar file from GDrive!\n",
        "                    if os.path.isfile('/tmp/pymol_colab_20230509.tar.gz'):\n",
        "                        os.remove('/tmp/pymol_colab_20230509.tar.gz')\n",
        "                    # File ID extracted from the Google Drive link\n",
        "                    file_id = \"1Jf2ydKBKju2OvKou57v8hs-bFlNbIbS7\"\n",
        "                    output_file = \"/tmp/pymol_colab_20230509.tar.gz\"\n",
        "\n",
        "                    # Download tar file from Google Drive using gdown\n",
        "                    if os.path.isfile(output_file):\n",
        "                        os.remove(output_file)\n",
        "\n",
        "                    # Using gdown to download the pymol binaries\n",
        "                    !gdown --id {file_id} -O {output_file}\n",
        "\n",
        "                    # Extract the tar file\n",
        "                    !tar -xf {output_file} -C /tmp/\n",
        "\n",
        "                    # Change directory\n",
        "                    %cd /tmp/pymol-open-source/\n",
        "\n",
        "                    !python3 setup.py install\n",
        "                    os.chdir('/content')\n",
        "                    import pymol, prody\n",
        "                    import pyfastx as pyfx\n",
        "                    clear_output()\n",
        "                    check_time = time.perf_counter()\n",
        "                    print(\"PyMOL is Installed. Dependency Installation Completed.\")\n",
        "                    print(\"Total Time Elapsed: \", str(datetime.timedelta(seconds=int(check_time - start_time))),\" minutes.\")\n",
        "                    print(\"Dependencies Configured!\")\n",
        "                    button_start_app.description = \"Click Here to Start AlphaCross-XL\"\n",
        "                    button_start_app.disabled = False\n",
        "                    print(\"AlphaCross-XL is Initialized!\")\n",
        "                    print(pymol.get_version_message())\n",
        "                    print(\"ProDy Version: \", prody.__version__, \", PyFastX Version: \", pyfx.__version__)\n",
        "                    print(\"Base Directory: \", main_base_dir)\n",
        "\n",
        "                except:\n",
        "                    clear_output()\n",
        "                    print(\"Initialization Terminated! This shouldn't happen, unless you manually interrupted the execution.\")\n",
        "                    print(\"Fatal Error Installing Dependenices\")\n",
        "                    button_start_app.description = \"Error Initializing AlphaCross-XL Dependencies. Please contact Development Team\"\n",
        "                    #button_start_app.disabled = False\n",
        "    configure_dependencies()\n",
        "\n",
        "\n",
        "\n",
        "alphacrossxl_main()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kdd-Wq6LtbWG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}