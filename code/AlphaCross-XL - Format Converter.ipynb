{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AlphaCross-XL Format Converter\n",
        "\n",
        "AlphaCross-XL uses 'Peptide-centric Format' for parsing the position of the cross-linking residues of the protein.\n",
        "\n",
        "This script provides certain functionality that allows conversion of 'Protein-centric Format' to 'Peptide-centric Format' for use in AlphaCross-XL\n",
        "\n",
        "This script is given as a foundation and uses the following assumptions.\n",
        "- The cross-linking position is based on 0-indexed position of the residue in the protein.\n",
        "- The cross-linking peptides are mentioned\n",
        "- Reference Protein Sequence for the chosen species is from UniProt\n",
        "- Multiple cross-links between the same two peptides are given on a single line with a unique character, which is termed as \"separator\"\n",
        "\n",
        "\n",
        "### Dependencies\n",
        "You need the following Python Packages\n",
        "- Pandas\n",
        "- ProDy (installed in the following block)\n",
        "- PyFastx (installed in the following block)\n",
        "- requests, os, shutil, json (should come along with you python distribution)\n",
        "\n",
        "### NOTE\n",
        "- If Colab asks you to restart the session, you can do so.\n",
        "- If you are running this script locally, you only need to run the pip install once!\n",
        "- If you are running locally, comment the line \"os.chdir('/content')\" in the second block\n",
        "\n"
      ],
      "metadata": {
        "id": "CspGGnT62PlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prody pyfastx"
      ],
      "metadata": {
        "id": "FbsYEqBKVEis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHNAa6tw2DqH"
      },
      "outputs": [],
      "source": [
        "import requests, json\n",
        "import os, pathlib, shutil\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Only for Google Colab\n",
        "# Comment this out if not on Colab\n",
        "os.chdir('/content/')\n",
        "######################\n",
        "\n",
        "class FormatXLChange():\n",
        "    def __init__(self,\n",
        "                 input_uniprot_entry,\n",
        "                 input_xl_peptide_a,\n",
        "                 input_xl_peptide_b,\n",
        "                 input_xl_peptide_link_site_data_a,\n",
        "                 input_xl_peptide_link_site_data_b,\n",
        "                 input_xl_peptide_link_site_separator,\n",
        "                ):\n",
        "        # Input Data\n",
        "        self.input_uniprot_entry = input_uniprot_entry\n",
        "        self.input_xl_peptide_a = input_xl_peptide_a\n",
        "        self.input_xl_peptide_b = input_xl_peptide_b\n",
        "        self.input_xl_peptide_link_site_a = input_xl_peptide_link_site_data_a\n",
        "        self.input_xl_peptide_link_site_b = input_xl_peptide_link_site_data_b\n",
        "        self.input_xl_peptide_link_site_separator = input_xl_peptide_link_site_separator\n",
        "\n",
        "        self.base_dir = os.getcwd()\n",
        "\n",
        "        # Input UniProt Entry Data\n",
        "        self.uniprot_entry_type = None\n",
        "\n",
        "        # UniProt Entry Sequence Data\n",
        "        self.uniprot_entry_sequence_data = None\n",
        "        self.uniprot_entry_sequence_value = None\n",
        "        self.uniprot_entry_sequence_length = None\n",
        "\n",
        "        # XL Peptides Data\n",
        "        self.xl_peptide_a_found_unique = None\n",
        "        self.xl_peptide_b_found_unique = None\n",
        "        self.xl_peptide_a_found_multiple = None\n",
        "        self.xl_peptide_b_found_multiple = None\n",
        "        self.xl_peptide_a_start_residue_num = None\n",
        "        self.xl_peptide_b_start_residue_num = None\n",
        "        self.xl_peptide_a_end_residue_num = None\n",
        "        self.xl_peptide_b_end_residue_num = None\n",
        "\n",
        "\n",
        "    # Helper Functions\n",
        "    def _get_peptide_match_start_list(self, xl_peptide_sequence, reference_sequence):\n",
        "        xl_peptide_re = re.compile(xl_peptide_sequence)\n",
        "\n",
        "        peptide_match_start_list = []\n",
        "        for m in xl_peptide_re.finditer(reference_sequence):\n",
        "            peptide_match_start_list.append(m.start())\n",
        "        return peptide_match_start_list\n",
        "\n",
        "    def _check_peptide_uniqueness(self, xl_peptide_seq, xl_peptide_id, xl_peptide_match_start_list):\n",
        "        if (len(xl_peptide_match_start_list) == 0):\n",
        "            xl_peptide_found_unique = False\n",
        "            xl_peptide_found_multiple = False\n",
        "            print(f'XL Peptide {xl_peptide_id}: {xl_peptide_seq} not found in the protein sequence!')\n",
        "        elif (len(xl_peptide_match_start_list) == 1):\n",
        "            xl_peptide_found_unique = True\n",
        "            xl_peptide_found_multiple = False\n",
        "            print(f'XL Peptide {xl_peptide_id}: {xl_peptide_seq} found uniquely in the protein sequence!')\n",
        "        else:\n",
        "            xl_peptide_found_unique = False\n",
        "            xl_peptide_found_multiple = True\n",
        "            print(f'XL Peptide {xl_peptide_id}: {xl_peptide_seq} found multiple times in the protein sequence!')\n",
        "        return xl_peptide_found_unique, xl_peptide_found_multiple\n",
        "\n",
        "    def _set_peptide_start_end_residue_num(self, xl_peptide_id, xl_peptide_match_start_list, xl_peptide_length):\n",
        "        if xl_peptide_id == 'A':\n",
        "            if (self.xl_peptide_a_found_unique):\n",
        "                self.xl_peptide_a_start_residue_num = xl_peptide_match_start_list[0]\n",
        "                self.xl_peptide_a_end_residue_num = self.xl_peptide_a_start_residue_num + xl_peptide_length\n",
        "            elif (self.xl_peptide_a_found_multiple):\n",
        "                xl_peptide_match_end_list = []\n",
        "                for start_residue_num in xl_peptide_match_start_list:\n",
        "                    xl_peptide_match_end_list.append(start_residue_num + xl_peptide_length)\n",
        "                self.xl_peptide_a_start_residue_num = xl_peptide_match_start_list\n",
        "                self.xl_peptide_a_end_residue_num = xl_peptide_match_end_list\n",
        "            else:\n",
        "                 self.xl_peptide_a_start_residue_num = None\n",
        "                 self.xl_peptide_a_end_residue_num = None\n",
        "        elif xl_peptide_id == 'B':\n",
        "            if (self.xl_peptide_b_found_unique):\n",
        "                self.xl_peptide_b_start_residue_num = xl_peptide_match_start_list[0]\n",
        "                self.xl_peptide_b_end_residue_num = self.xl_peptide_b_start_residue_num + xl_peptide_length\n",
        "            elif (self.xl_peptide_b_found_multiple):\n",
        "                xl_peptide_match_end_list = []\n",
        "                for start_residue_num in xl_peptide_match_start_list:\n",
        "                    xl_peptide_match_end_list.append(start_residue_num + xl_peptide_length)\n",
        "                self.xl_peptide_b_start_residue_num = xl_peptide_match_start_list\n",
        "                self.xl_peptide_b_end_residue_num = xl_peptide_match_end_list\n",
        "            else:\n",
        "                self.xl_peptide_b_start_residue_num = None\n",
        "                self.xl_peptide_b_end_residue_num = None\n",
        "        else:\n",
        "            raise Exception(f'XL Peptide ID can only be A or B, got ID: {xl_peptide_id}')\n",
        "\n",
        "    def process_input_uniprot_entry(self):\n",
        "        uniprot_api_return_sturcture_3d_sequence_path = f'https://rest.uniprot.org/uniprotkb/search?query=accession:{self.input_uniprot_entry}&fields=sequence'\n",
        "        try:\n",
        "            response = requests.get(uniprot_api_return_sturcture_3d_sequence_path)\n",
        "            response_data = json.loads(response.text)\n",
        "            if len(response_data['results']) == 0:\n",
        "                print(f\"The UniProt ID: {self.input_uniprot_entry} didn't return any results in the UniProtKB Database\")\n",
        "                if 'error' in response_data.keys():\n",
        "                    print(f\"UniProt Error: {response_data['error']}\")\n",
        "                #print(f\"Execution Terminated. No UniProt Entries\")\n",
        "            elif len(response_data['results']) > 1:\n",
        "                print(f\"The The UniProt ID: {self.input_uniprot_entry} returned multiple primary_accessions in the UniProtKB Database\")\n",
        "                print(f\"Execution Terminated. Multiple UniProt Entries\")\n",
        "\n",
        "            else:\n",
        "                print(f\"The UniProt ID: {self.input_uniprot_entry} returned a unique entry in the database!\")\n",
        "                uniprot_id_entry_data = response_data['results'][0]\n",
        "                self.uniprot_entry_type = uniprot_id_entry_data[\"entryType\"]\n",
        "                print(f\"The UniProt ID: {self.input_uniprot_entry}'s UniProtKB Entry Type is: {self.uniprot_entry_type}\")\n",
        "                try:\n",
        "                    self.uniprot_entry_sequence_data = uniprot_id_entry_data[\"sequence\"]\n",
        "\n",
        "                    print(f\"The UniProt ID: {self.input_uniprot_entry}'s Sequence Length is: {self.uniprot_entry_sequence_data['length']}\")\n",
        "                except:\n",
        "                    #print(e)\n",
        "                    print(f\"The UniProt ID: {self.input_uniprot_entry} returned no sequence data!\")\n",
        "                    print(f\"Execution Terminated. No sequence Data found for {self.input_uniprot_entry}.\")\n",
        "        except:\n",
        "            #print(e)\n",
        "            print(\"UniProt Endpoint Unavailable/API Path Malformed!\")\n",
        "            print(f\"Execution Stopped\")\n",
        "\n",
        "    def process_peptide_sequences_for_given_uniprot_entry_sequence(self):\n",
        "        self.uniprot_entry_sequence_value = self.uniprot_entry_sequence_data['value']\n",
        "        self.uniprot_entry_sequence_length = self.uniprot_entry_sequence_data['length']\n",
        "\n",
        "        xl_peptide_a_length = len(self.input_xl_peptide_a)\n",
        "        xl_peptide_b_length = len(self.input_xl_peptide_b)\n",
        "        xl_peptide_a_re = re.compile(self.input_xl_peptide_a)\n",
        "        xl_peptide_b_re = re.compile(self.input_xl_peptide_b)\n",
        "        peptide_match_start_list_a = self._get_peptide_match_start_list(self.input_xl_peptide_a, self.uniprot_entry_sequence_value)\n",
        "        peptide_match_start_list_b = self._get_peptide_match_start_list(self.input_xl_peptide_b, self.uniprot_entry_sequence_value)\n",
        "\n",
        "        # Peptide A\n",
        "        self.xl_peptide_a_found_unique, self.xl_peptide_a_found_multiple = self._check_peptide_uniqueness(\n",
        "            self.input_xl_peptide_a,\n",
        "            'A',\n",
        "            peptide_match_start_list_a)\n",
        "        self._set_peptide_start_end_residue_num(\n",
        "            'A',\n",
        "            peptide_match_start_list_a,\n",
        "            xl_peptide_a_length\n",
        "        )\n",
        "        # Peptide B\n",
        "        self.xl_peptide_b_found_unique, self.xl_peptide_b_found_multiple = self._check_peptide_uniqueness(\n",
        "            self.input_xl_peptide_b,\n",
        "            'B',\n",
        "            peptide_match_start_list_b)\n",
        "        self._set_peptide_start_end_residue_num(\n",
        "            'B',\n",
        "            peptide_match_start_list_b,\n",
        "            xl_peptide_b_length\n",
        "        )\n",
        "\n",
        "    def get_relative_link_sites(self):\n",
        "        def _process_link_sites(link_site_data, separator):\n",
        "            # Remove 'K' prefix and split if multiple sites\n",
        "            sites = link_site_data.replace('K', '').split(separator)\n",
        "            print(f\"The link sites are: {sites}\")\n",
        "            return [int(site) for site in sites]\n",
        "\n",
        "\n",
        "        def _calculate_relative_positions(link_sites, start_pos, peptide_seq):\n",
        "            relative_positions = []\n",
        "            for site in link_sites:\n",
        "                # Convert absolute position to relative (0-based)\n",
        "                absolute_pos = site - 1\n",
        "                relative_pos = absolute_pos - start_pos\n",
        "                # Verify the link site corresponds to a lysine\n",
        "                if peptide_seq[relative_pos] != 'K':\n",
        "                    raise ValueError(f\"Link site {site} does not correspond to a lysine in peptide {peptide_seq}\")\n",
        "                relative_positions.append(relative_pos + 1)  # Convert back to 1-based\n",
        "            return relative_positions\n",
        "\n",
        "        results = {\n",
        "            'peptide_a': None,\n",
        "            'peptide_b': None\n",
        "        }\n",
        "\n",
        "        # Process peptide A\n",
        "        if self.xl_peptide_a_found_unique and self.xl_peptide_a_start_residue_num is not None:\n",
        "            link_sites_a = _process_link_sites(self.input_xl_peptide_link_site_a,\n",
        "                                            self.input_xl_peptide_link_site_separator)\n",
        "            results['peptide_a'] = _calculate_relative_positions(\n",
        "                link_sites_a,\n",
        "                self.xl_peptide_a_start_residue_num,\n",
        "                self.input_xl_peptide_a\n",
        "            )\n",
        "\n",
        "        # Process peptide B\n",
        "        if self.xl_peptide_b_found_unique and self.xl_peptide_b_start_residue_num is not None:\n",
        "            link_sites_b = _process_link_sites(self.input_xl_peptide_link_site_b,\n",
        "                                            self.input_xl_peptide_link_site_separator)\n",
        "            results['peptide_b'] = _calculate_relative_positions(\n",
        "                link_sites_b,\n",
        "                self.xl_peptide_b_start_residue_num,\n",
        "                self.input_xl_peptide_b\n",
        "            )\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "def process_crosslinks(data_file):\n",
        "    \"\"\"Process cross-linked peptides from CSV/XLSX file\"\"\"\n",
        "    # First parse the file\n",
        "    ## Get the file extension in lowercase\n",
        "    file_extension = os.path.splitext(data_file)[1].lower()\n",
        "\n",
        "    try:\n",
        "        if file_extension in ['.csv']:\n",
        "            df = pd.read_csv(data_file)\n",
        "        elif file_extension in ['.xlsx', '.xls']:\n",
        "            df = pd.read_excel(data_file)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error reading file {data_file}: {str(e)}\")\n",
        "\n",
        "\n",
        "    # Initialize list to store processed results\n",
        "    results = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Extract data from row\n",
        "        xl_data = {\n",
        "            'peptide_a': row['Peptide-A'],\n",
        "            'link_site_a': row['Link-Site-A'],\n",
        "            'peptide_b': row['Peptide-B'],\n",
        "            'link_site_b': row['Link-Site-B'],\n",
        "            'uniprot_id': row['uniprotID'],\n",
        "            'xl_type': row['X-link type']\n",
        "        }\n",
        "\n",
        "        # Create FormatXLChange instance for this cross-link\n",
        "        xlc = FormatXLChange(\n",
        "            input_uniprot_entry=xl_data['uniprot_id'],\n",
        "            input_xl_peptide_a=xl_data['peptide_a'],\n",
        "            input_xl_peptide_b=xl_data['peptide_b'],\n",
        "            input_xl_peptide_link_site_data_a=xl_data['link_site_a'],\n",
        "            input_xl_peptide_link_site_data_b=xl_data['link_site_b'],\n",
        "            input_xl_peptide_link_site_separator=';'\n",
        "        )\n",
        "\n",
        "        # Process the UniProt entry\n",
        "        xlc.process_input_uniprot_entry()\n",
        "\n",
        "        # Get peptide status\n",
        "        xlc.process_peptide_sequences_for_given_uniprot_entry_sequence()\n",
        "\n",
        "        # Get relative link sites\n",
        "        relative_positions = xlc.get_relative_link_sites()\n",
        "\n",
        "        # Store results\n",
        "        results.append({\n",
        "            'row_index': index,\n",
        "            'uniprot_id': xl_data['uniprot_id'],\n",
        "            'peptide_a': xl_data['peptide_a'],\n",
        "            'peptide_b': xl_data['peptide_b'],\n",
        "            'absolute_link_site_a': xl_data['link_site_a'],\n",
        "            'absolute_link_site_b': xl_data['link_site_b'],\n",
        "            'relative_link_site_a': relative_positions['peptide_a'],\n",
        "            'relative_link_site_b': relative_positions['peptide_b']\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "def save_crosslink_results(results, output_file=\"processed_crosslinks.csv\"):\n",
        "    # Initialize list to store expanded results\n",
        "    expanded_results = []\n",
        "\n",
        "    for result in results:\n",
        "        # Get link sites for peptides A and B\n",
        "        sites_a = result['absolute_link_site_a'].replace('K', '').split(';')\n",
        "        sites_b = result['absolute_link_site_b'].replace('K', '').split(';')\n",
        "        rel_sites_a = result['relative_link_site_a'] if isinstance(result['relative_link_site_a'], list) else [result['relative_link_site_a']]\n",
        "        rel_sites_b = result['relative_link_site_b'] if isinstance(result['relative_link_site_b'], list) else [result['relative_link_site_b']]\n",
        "\n",
        "        # Create cartesian product of link sites\n",
        "        for i, (abs_site_a, rel_site_a) in enumerate(zip(sites_a, rel_sites_a)):\n",
        "            for j, (abs_site_b, rel_site_b) in enumerate(zip(sites_b, rel_sites_b)):\n",
        "                # Get amino acids at link sites\n",
        "                aa_a = result['peptide_a'][rel_site_a - 1] if rel_site_a else 'K'\n",
        "                aa_b = result['peptide_b'][rel_site_b - 1] if rel_site_b else 'K'\n",
        "\n",
        "                expanded_results.append({\n",
        "                    'row_index': result['row_index'],\n",
        "                    'uniprot_id': result['uniprot_id'],\n",
        "                    'peptide_a': result['peptide_a'],\n",
        "                    'peptide_b': result['peptide_b'],\n",
        "                    'absolute_link_site_a': f'{aa_a}{abs_site_a}',\n",
        "                    'absolute_link_site_b': f'{aa_b}{abs_site_b}',\n",
        "                    'relative_link_site_a': f'{aa_a}{rel_site_a}',\n",
        "                    'relative_link_site_b': f'{aa_b}{rel_site_b}'\n",
        "                })\n",
        "\n",
        "    # Convert to DataFrame and save\n",
        "    df = pd.DataFrame(expanded_results)\n",
        "\n",
        "    # Define column order\n",
        "    columns = [\n",
        "        'row_index',\n",
        "        'uniprot_id',\n",
        "        'peptide_a',\n",
        "        'peptide_b',\n",
        "        'absolute_link_site_a',\n",
        "        'absolute_link_site_b',\n",
        "        'relative_link_site_a',\n",
        "        'relative_link_site_b'\n",
        "    ]\n",
        "\n",
        "    # Reorder columns and save to CSV\n",
        "    df = df[columns]\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    return output_file\n",
        "\n",
        "def save_crosslink_results(results, output_file=\"processed_crosslinks.csv\"):\n",
        "    # Initialize list to store expanded results\n",
        "    expanded_results = []\n",
        "\n",
        "    for result in results:\n",
        "        # Get link sites for peptides A and B\n",
        "        sites_a = result['absolute_link_site_a'].replace('K', '').split(';')\n",
        "        sites_b = result['absolute_link_site_b'].replace('K', '').split(';')\n",
        "        rel_sites_a = result['relative_link_site_a'] if isinstance(result['relative_link_site_a'], list) else [result['relative_link_site_a']]\n",
        "        rel_sites_b = result['relative_link_site_b'] if isinstance(result['relative_link_site_b'], list) else [result['relative_link_site_b']]\n",
        "\n",
        "        # Create cartesian product of link sites\n",
        "        for i, (abs_site_a, rel_site_a) in enumerate(zip(sites_a, rel_sites_a)):\n",
        "            for j, (abs_site_b, rel_site_b) in enumerate(zip(sites_b, rel_sites_b)):\n",
        "                # Get amino acids at link sites\n",
        "                aa_a = result['peptide_a'][rel_site_a - 1] if rel_site_a else 'K'\n",
        "                aa_b = result['peptide_b'][rel_site_b - 1] if rel_site_b else 'K'\n",
        "\n",
        "                expanded_results.append({\n",
        "                    'row_index': result['row_index'],\n",
        "                    'uniprot_id': result['uniprot_id'],\n",
        "                    'peptide_a': result['peptide_a'],\n",
        "                    'peptide_b': result['peptide_b'],\n",
        "                    'absolute_link_site_a': f'{aa_a}{abs_site_a}',\n",
        "                    'absolute_link_site_b': f'{aa_b}{abs_site_b}',\n",
        "                    'relative_link_site_a': f'{aa_a}{rel_site_a}',\n",
        "                    'relative_link_site_b': f'{aa_b}{rel_site_b}'\n",
        "                })\n",
        "\n",
        "    # Convert to DataFrame and save\n",
        "    df = pd.DataFrame(expanded_results)\n",
        "\n",
        "    # Define column order\n",
        "    columns = [\n",
        "        'row_index',\n",
        "        'uniprot_id',\n",
        "        'peptide_a',\n",
        "        'peptide_b',\n",
        "        'absolute_link_site_a',\n",
        "        'absolute_link_site_b',\n",
        "        'relative_link_site_a',\n",
        "        'relative_link_site_b'\n",
        "    ]\n",
        "\n",
        "    # Reorder columns and save to CSV\n",
        "    df = df[columns]\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    return output_file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single pair usage\n",
        "\n",
        "Following code block demonstrates the script's ability to work on a single pair of cross-linking peptides, with multiple crosslinks, separated using the separator ';'\n",
        "\n",
        "The output shows the relative positions of the cross-linking residues using the peptide-centric approach."
      ],
      "metadata": {
        "id": "kvghsJIj9y29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single Usage\n",
        "xlc = FormatXLChange(\n",
        "    input_uniprot_entry=\"P63104\",\n",
        "    input_xl_peptide_a=\"VVSSIEQKTEGAEK\",\n",
        "    input_xl_peptide_b=\"KQQMAR\",\n",
        "    input_xl_peptide_link_site_data_a=\"K68;K74\",\n",
        "    input_xl_peptide_link_site_data_b=\"K75\",\n",
        "    input_xl_peptide_link_site_separator=\";\"\n",
        ")\n",
        "xlc.process_input_uniprot_entry()\n",
        "xlc.process_peptide_sequences_for_given_uniprot_entry_sequence()\n",
        "relative_positions = xlc.get_relative_link_sites()\n",
        "\n",
        "relative_positions"
      ],
      "metadata": {
        "id": "jZ_bWt0wWWOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bulk conversion using a XLSX/CSV File\n",
        "You can also bulk convert multiple pairs of cross-link using the following code snippet (Make sure you edit the file name)\n",
        "\n",
        "An example file for the format converter is given in the \"example\" subdirectory of the AlphaCross-XL GitHub\n",
        "\n",
        "### File Format\n",
        "The file should have the following columns, which are self-explantory (and the columns should exactly match!)\n",
        "- Peptide-A\n",
        "- Link-Site-A\n",
        "- Peptide-B\n",
        "- Link-Site-B\n",
        "- X-link type\n",
        "\n",
        "#### IMPORTANT\n",
        "The other columns of the input file will be lost! (Please use the row numbers to recuperate the lost information in the updated file)"
      ],
      "metadata": {
        "id": "S-4PkmS8AKQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only for Colab\n",
        "os.chdir('/content/')\n",
        "main_base_dir = os.getcwd()\n",
        "csv_file = \"input_csv_formatxlchange.csv\"\n",
        "results = process_crosslinks(os.path.join(main_base_dir, csv_file))\n",
        "\n",
        "# Print first few results\n",
        "for result in results[:3]:\n",
        "    print(f\"\\nProcessing cross-link for {result['uniprot_id']}:\")\n",
        "    print(f\"Peptide A: {result['peptide_a']}\")\n",
        "    print(f\"Absolute link site A: {result['absolute_link_site_a']}\")\n",
        "    print(f\"Relative link site A: {result['relative_link_site_a']}\")\n",
        "    print(f\"Peptide B: {result['peptide_b']}\")\n",
        "    print(f\"Absolute link site B: {result['absolute_link_site_b']}\")\n",
        "    print(f\"Relative link site B: {result['relative_link_site_b']}\")\n",
        "# Save the file\n",
        "save_crosslink_results(results, output_file=\"processed_crosslinks.csv\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Zem_UDZUzS9b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}